<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>SWebber IT Services</title>
    <link>http://swebber.me/categories/postgresql/index.xml</link>
    <description>Recent content on SWebber IT Services</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <atom:link href="http://swebber.me/categories/postgresql/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>O Autovacuum do PostgreSQL não é o inimigo!</title>
      <link>http://swebber.me/blog/2016/11/14/autovacuum-nao-e-o-inimigo/</link>
      <pubDate>Mon, 14 Nov 2016 14:10:41 -0200</pubDate>
      
      <guid>http://swebber.me/blog/2016/11/14/autovacuum-nao-e-o-inimigo/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ATENÇÃO!&lt;/strong&gt; Este post é uma tradução para Português do Brasil do &lt;a href=&#34;https://www.citusdata.com&#34;&gt;blog da citusdata&lt;/a&gt;, escrito pelo Sr. Joe Nelson. O post original pode ser encontrado na URL abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/&#34;&gt;https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fique a vontade para comentar quaisquer problemas na tradução.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;É um equívoco comum que workloads com grandes volumes de leituras e escritas no PostgreSQL inevitavelmente causam ineficiencia no banco de dados. Nós ouvimos casos aonde os usuários encontram lentidões fazendo apenas algumas centenas de gravações por segundo e recorrem a sistemas como Dynamo ou Cassandra por frustração. No entanto, o PostgreSQL pode lidar com essas cargas de trabalho sem nenhum problema, desde que ele esteja configurado corretamente.&lt;/p&gt;

&lt;p&gt;O problema deriva do que é conhecido como &amp;ldquo;inchaço&amp;rdquo;, um fenômeno do PostgreSQL e de outros bancos de dados MVCC que causa o aumento do espaço em disco e uma baixa no desempenho. Vamos ver como o AutoVACUUM, uma ferramenta que combate o inchaço, é tipicamente incompreendida e mal configurada. Ao falar num baixo nível sobre os componentes internos do PostgreSQL vamos chegar numa melhor configuração para o AutoVACUUM. Finalmente vamos considerar como distribuir os dados sob um cluster PostgreSQL como o Citus também pode combater o inchaço.&lt;/p&gt;

&lt;h2 id=&#34;problemas-no-paraíso-do-mvcc&#34;&gt;Problemas no paraíso do MVCC&lt;/h2&gt;

&lt;p&gt;Aqui o problema começa: Arquitetos de bancos de dados desejam permitir transações read-only num banco de dados para retornar os dados sem bloquear as atualizações concorrentes. Fazendo isso, se reduz a latência das requisições em ambientes com leitura pesada, comum em aplicações web.&lt;/p&gt;

&lt;p&gt;Entretanto, para permitir que leituras contínuas prossigam sem pausa, é necessário manter um snapshot diferente do mundo para algumas requisições e finalmente conciliar as diferenças. Essas &amp;ldquo;pequenas mentiras&amp;rdquo; ficam sujeitas a uma penalidade de espaço, familiar a todas as mentiras - você vai precisar de uma boa memória para manter o histórico em ordem.&lt;/p&gt;

&lt;p&gt;O PostgreSQL e outros bancos de dados relacionais usam uma técnica chamada Multi-Version Concurrency Control (MVCC) para manter o controle de cada transação e a penalidade de espaço do MVCC é chamada de inchaço. O PostgreSQL é uma máquina de inchaço e ele vai inchar sem escrúpulos. O PostgreSQL precisa de ajuda de uma ferramenta externa chamada &lt;code&gt;VACUUM&lt;/code&gt; para ter uma chance de limpar essa &amp;ldquo;sujeira&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Por razões que vamos ver mais tarde, tabelas e índices inchados não somente disperdiçam espaço mas também deixam as consultas mais lentas. Então isso não é só uma questão de conseguir um disco rigido maior e esquecer sobre o inchaço. Onde há atualizações nos dados há inchaço e é com você executar o &lt;code&gt;VACUUM&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Não é tão ruim quanto costumava ser. Num passado distante (antes do PostgreSQL 8), os DBAs tinham que executar o &lt;code&gt;VACUUM&lt;/code&gt; manualmente. Eles tinham que balancear o consumo de recursos contra a carga (load average) do banco de dados existente para decidir quando executa-lo e potencialmente quando interrompe-lo. Hoje em dia podemos configurar o daemon do &lt;code&gt;AutoVACUUM&lt;/code&gt; para executar essas limpezas nos momentos mais oportunos.&lt;/p&gt;

&lt;p&gt;O &lt;code&gt;AutoVACUUM&lt;/code&gt; funciona bem quando configurado corretamente. Entretando, suas configurações padrão são apropriadas para bancos de dados com algumas centenas de mega bytes de tamanho e não é agressivo o bastante para grandes bancos de dados. Em ambientes de produção ele começa a ficar pra trás.&lt;/p&gt;

&lt;p&gt;Quando o &lt;code&gt;VACUUM&lt;/code&gt; ficar pra trás ele vai consumir mais recursos quando ele é executado e isso vai interferir na operação normal das consultas. Isso pode levar à um circulo vicioso aonde os administradores de bancos de dados reconfiguram erroniamente o &amp;ldquo; devorador de recursos &lt;code&gt;AutoVACUUM&lt;/code&gt;&amp;rdquo; pra rodar com menos frequência ou não rodar mais. O &lt;code&gt;AutoVACUUM&lt;/code&gt; não é o ínimigo e &lt;strong&gt;desabilitá-lo é desastroso&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;a-magreza-no-inchaço&#34;&gt;A magreza no inchaço&lt;/h2&gt;

&lt;p&gt;O PostgreSQL numera cada nova transação com um identificador incremental (&lt;code&gt;txid&lt;/code&gt;). Todas as linhas na tabela também possuem colunas escondidas (&lt;code&gt;xmin&lt;/code&gt;, &lt;code&gt;xmax&lt;/code&gt;) gravando o &lt;code&gt;transaction id&lt;/code&gt; mínimo e máximo que são permitidos ver o registro. Você pode imaginar o comando &lt;code&gt;SELECT&lt;/code&gt; incluindo implicitamente &lt;code&gt;WHERE xmin &amp;lt;= txid_current() AND (xmax = 0 OR txid_current() &amp;lt; xmax)&lt;/code&gt;. Registros que não possuem nenhuma transação ativa ou no futuro podem ser consideradas &amp;ldquo;mortos&amp;rdquo;. Isso significa que não há transações ativas com &lt;code&gt;xmin ≤ txid &amp;lt; xmax&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Novos registros ou registros atualizados utilizam o &lt;code&gt;txid&lt;/code&gt; da transação que o criou para o seu &lt;code&gt;xmin&lt;/code&gt; e registros apagados definem o &lt;code&gt;xmax&lt;/code&gt; com o &lt;code&gt;txid&lt;/code&gt; que o deletou.&lt;/p&gt;

&lt;p&gt;Ilustração rápida:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;begin;

select txid_current(); -- supostamente vai retornar 1
create table foo (bar integer);
insert into foo (bar) values (100);

select xmin, xmax from foo;

commit;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vai retornar:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;┌──────┬──────┐
│ xmin │ xmax │
├──────┼──────┤
│    1 │    0 │
└──────┴──────┘
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Se atualizarmos o registro, o &lt;code&gt;xmin&lt;/code&gt; vai avançar:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;begin;

update foo set bar = 200;
select xmin, xmax from foo;

commit;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Isso retorna:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;┌──────┬──────┐
│ xmin │ xmax │
├──────┼──────┤
│    2 │    0 │
└──────┴──────┘
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O que não é exibido é que agora há um registro morto na tabela. Atualizando o registro efetivamente apaga-o e insere-0 com os valores alterados. O registro que estamos vendo foi recentemente inserido (pelo  &lt;code&gt;txid&lt;/code&gt; 2) e o registro original está no disco com &lt;code&gt;xmix=1, xmax=2&lt;/code&gt;. Podemos confirmar perguntando por informações sobre as tuplas (registros) nessa tabela.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create extension pgstattuple;

select tuple_count, dead_tuple_count from pgstattuple(&#39;public.foo&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;┌─────────────┬──────────────────┐
│ tuple_count │ dead_tuple_count │
├─────────────┼──────────────────┤
│           1 │                1 │
└─────────────┴──────────────────┘
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O PostgreSQL também provê uma API de baixo nível para ver informações sobre o armazenmaneto físico das páginas de bancos de dados (pedaços da tabela armazenados no disco). Essa API nos permite ver o &lt;code&gt;xmin&lt;/code&gt; e &lt;code&gt;xmax&lt;/code&gt; de todas as linhas e, apesar de algumas considerações de segurança, os valores dos registros apagados não sÃo visíveis.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create extension pageinspect;

select t_xmin, t_xmax from heap_page_items(get_raw_page(&#39;foo&#39;, 0));
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;┌────────┬────────┐
│ t_xmin │ t_xmax │
├────────┼────────┤
│      1 │      2 │
│      2 │      0 │
└────────┴────────┘
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nesse ponto você pode ver um jeito de gerar o inchaço: é só continuamente atualizar muitos registros de uma tabela. Se o &lt;code&gt;AutoVACUUM&lt;/code&gt; foi desabilitado, o tamanho da tabela vai continuar a aumentar mesmo que o número de registros visiveis continue o mesmo. Um outro jeito de causar o inchaço é inserir uma grande quantidade de registros dentro de uma transação mas executar o &lt;code&gt;ROLLBACK&lt;/code&gt; ao invés do &lt;code&gt;COMMIT&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Se o &lt;code&gt;AutoVACUUM&lt;/code&gt; está rodando, ele pode limpar esses registros mortos &lt;em&gt;a menos que&amp;hellip;&lt;/em&gt; os registros apagados são impedidos de morrer! Nesse cenário de filmes de terror uma transação está rodando por muito tempo (como uma consulta analítica) e seus &lt;code&gt;txid&lt;/code&gt; previnem registros como de serem marcados como mortos, mesmo quando apagados por outro comando. A consulta que está rodando a muito tempo nem precisa consultar os registros apagados, a presença dos registros quando a consulta iniciou garante que elas não podem ser removidas. Combinar OLTP e consultas analíticas que rodam por muito tempo é um cocktail perigoso.&lt;/p&gt;

&lt;p&gt;Fora o intratável apocalipse zumbi acíma, o &lt;code&gt;AutoVACUUM&lt;/code&gt; pode deixar as coisas sob controler com a configuração adequada. Vamos ver algumas consenquências do inchaço antes de considerar o &lt;code&gt;AutoVACUUM&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;o-inchaço-e-a-velocidade-das-consultas&#34;&gt;O inchaço e a velocidade das consultas&lt;/h2&gt;

&lt;p&gt;Além de simplismente ser um disperdício de espaço, o inchaço prejudica a velocidade da consulta. Cada tabela e seu índice é armazenado num array de páginas de tamanho fixo (normalmente de &lt;code&gt;8KB&lt;/code&gt;). Quando a consulta solicita os registros, o banco de dados carrega essas páginas na memória. Quanto mais registros mortos por página, mais &lt;code&gt;I/O&lt;/code&gt; é disperdiçado na carga dos dados para a memória. Por exemplo: &lt;strong&gt;uma leitura sequencial precisa carregar e passar por todos registros mortos&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;O inchaço também torna menos provavel que os registros ativos para consulta vão caber na memória todos de uma vez. Inchaços fazem registros vivos mais dispersos por página física e, consenquêntemente, mais páginas são necessárias em memória para o mesmo número de registros &amp;ldquo;vivos&amp;rdquo;. Isso causa swap e torna alguns algoritmos e planos de consulta inaceitaveis para execução.&lt;/p&gt;

&lt;p&gt;Um caso de inchaço desagradavel é o &lt;a href=&#34;https://www.postgresql.org/docs/current/static/catalogs.html&#34;&gt;próprio catálogo&lt;/a&gt; do PostgreSQL. &lt;strong&gt;O catalogo pode inchar por que eles também são tabelas.&lt;/strong&gt; Um jeito de causar isso acontecer é através das tabelas temporárias, constantemente criando e apagando. Isso causa constantes atualizações nas tabelas do catálogo. Quando o catálogo está inchado, as funções administrativas ficam lentas e até coisas como rodar um &lt;code&gt;\d&lt;/code&gt; no psql é lento.&lt;/p&gt;

&lt;p&gt;Índices ficam inchados também. Um índice é um mapeamento de chaves de valores de dados para identificadores de registros. Esses identificadores nomeiam a página do &lt;code&gt;heap&lt;/code&gt; (também conhecimento como o arquivo que a tabela é armazeada) e  o intervalo dentro da página. Cada registro é um objeto independente que precisa sua própria entrada no índice. &lt;strong&gt;Uma atualização no registro sempre cria uma nova entrada no índice para o registro&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;A degradação do desempenho dos índices é menos grave do que das tabelas por algumas razões. Uma entrada do índice que aponta para um registro morto pode ser marcado como morto. Isso deixa o índice inchado em tamanho mas não leva a fazer pesquisas desnecessárias no &lt;code&gt;heap&lt;/code&gt;. Atualizações nos registros do &lt;code&gt;heap&lt;/code&gt; que não afetam a(s) coluna(s) do índice usam uma técnica chamada HOT para fornecer ponteiros para os registros mortos para sua substituição. Isso permite consultas tu reutilizar antigas entradas no índice através do heap.&lt;/p&gt;

&lt;p&gt;As considerações do tamanho do inchaço do índice ainda são significativas. Por exemplo, um índice &lt;code&gt;btree&lt;/code&gt; consiste numa arvore binária de páginas (do mesmo tamanho de páginas que você encontra no &lt;code&gt;heap&lt;/code&gt;). A página folha contém valores e identificadores de registros. Atualizações aleatórias na tabela tendem a deixar o índice &lt;code&gt;btree&lt;/code&gt; em forma por que ele pode reutilizar as páginas. Entretanto, inserções ou atualizações assimétricas que afetam um lado da arvore,&lt;/p&gt;

&lt;p&gt;Para verificar se um índice btree é eficiente usando suas páginas você pode perguntar a função &lt;code&gt;pgstatindex&lt;/code&gt;. A média de densidade da folha é a porcentagem do uso da página de índice de folha:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT avg_leaf_density FROM pgstatindex(&#39;btree_index_name&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ajustando-o-autovacuum&#34;&gt;Ajustando o AutoVACUUM&lt;/h2&gt;

&lt;p&gt;O AutoVACUUM deixa o banco de dados rápido e em bom estado. Ele começa a trabalhar quando certas condições configuráveis são atingidas e faz uma pausa quando ele detecta que está sendo muito intrusivo para as consultas.&lt;/p&gt;

&lt;p&gt;Para todo banco de dados no cluster, o AutoVACUUM tenta iniciar um worker a cada &lt;code&gt;autovacuum_naptime&lt;/code&gt; (a cada minuto por padrão). Ele vai rodar no máximo &lt;code&gt;autovacuum_max_workers&lt;/code&gt; (3 por padrão) a cada vez.&lt;/p&gt;

&lt;p&gt;Cada worker procura por uma tabela que precisa de ajuda. O worker procura por tabelas aonde as estatíticas do PostgreSQL indicam um número grande o bastante de registros alterados ao tamanho da tabela. Cada worker em particular procura por uma tabela que filtra &lt;code&gt;[ESTIMATIVA DE REGISTROS INVALIDADOS] ≥ autovacuum_vacuum_scale_factor * [TAMANHO ESTIMADO DA TABELA] + autovacuum_vacuum_threshold&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;O worker começa removendo os registros mortos da tabela e compactando as páginas. Conforme cada worker avança, ele faz uma contagem de &amp;ldquo;I/O credits&amp;rdquo; que eles estão consumindo. Diferentes tipos de ações contam para créditos variáveis (os valores são configuráveis). Quando os créditos usados excedem o &lt;code&gt;autovacuum_vacuum_cost_limit&lt;/code&gt;, o AutoVACUUM pausa todos os workers em &lt;code&gt;autovacuum_vacuum_cost_delay&lt;/code&gt; milissegundos.&lt;/p&gt;

&lt;p&gt;Executar o vacuum é uma corrida contra o tempo. Quando compacta as páginas, o vacuum worker escaneia o &lt;code&gt;heap&lt;/code&gt; procurando por registros mortos e adiciona-os numa lista. Ele usa essa lista para primeiro apagar as entradas de ponteiro no índice para essas linhas e então, remove a linha do &lt;code&gt;heap&lt;/code&gt;. Se há muitos registros para limpar e &lt;code&gt;maintenance_work_mem&lt;/code&gt; é limitada, o worker não vai conseguir processar muitos registros mortos a cada execução e vai perder tempo repetindo esse processo com mais frequência.&lt;/p&gt;

&lt;p&gt;Isso explica uma maneira que o AutoVACUUM fica pra trás: quando há muitos registros mortos acumulados e o AutoVACUUM não possui &lt;code&gt;maintenance_work_mem&lt;/code&gt; o suficiente para removê-los rapidamente e além disso fica limitado ao &lt;code&gt;vacuum_cost_limit&lt;/code&gt;. Isso fica nítido em grandes tabelas no banco de dados. Os valores padrão no banco de dados para &lt;code&gt;autovacuum_vacuum_scale_factor = 0.2&lt;/code&gt; podem ser apropriados para pequenas tabelas, mas é muito grande para tabelas maiores. Você pode configurar o parâmetro por tabela:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;ALTER TABLE &amp;lt;tablename&amp;gt;
  SET autovacuum_vacuum_scale_factor = 0.01;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Isso quer dizer que, para tabelas com milhões de registros, o AutoVACUUM deve iniciar depois de 10 mil registros serem invalidados ao invés de dozentos mil. Isso ajuda a deixar o inchaço sob controle.&lt;/p&gt;

&lt;p&gt;AutoVACUUM também pode ficar pra trás quando há mais tabelas inchadas do que que &lt;code&gt;autovacuum_max_workers&lt;/code&gt; e todas as tabelas continuam a inchar. Workers não coneseguem chegar em todas as tabelas.&lt;/p&gt;

&lt;p&gt;Aqui há ajustes sensíveis ao AutoVACUUM. Eles não vão funcionar para todos os bancos de dados, é claro, mas vão te levar pra direção correta.&lt;/p&gt;

&lt;table class=&#34;table&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Variável&lt;/th&gt;
            &lt;th&gt;PG Default&lt;/th&gt;
            &lt;th&gt;Sugestão&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_max_workers&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;5&lt;/code&gt; ou &lt;code&gt;6&lt;/code&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;maintenance_work_mem&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;64MB&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;system ram * 3/(8*autovacuum max workers)&lt;/code&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_vacuum_scale_factor&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;0.2&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Para grandes tabelas, tente &lt;code&gt;0.01&lt;/code&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_vacuum_threshold&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;50&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Pode ser grande para tabelas pequenas&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_vacuum_cost_limit&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;200&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Provavelmente deixe assim&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_vacuum_cost_delay&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;20ms&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Você pode baixar caso esteja OK com mais cara de I/O durante o vacuum&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;fique-de-olho&#34;&gt;Fique de olho&lt;/h2&gt;

&lt;p&gt;Após ajustar as configurações do AutoVACUUM, você deve esperar e observar como o banco de dados responde. De fato, você pode querer observar o banco de dados durante um tempo &lt;em&gt;antes&lt;/em&gt; de ajustar as configurações pra evitar qualquer otimização prematura. Você deve procurar pela taxa de variação ou pela porcentagem de inchaço nas tabelas e índices.&lt;/p&gt;

&lt;p&gt;Utilize esses scripts pra coletar métricas: &lt;a href=&#34;https://github.com/pgexperts/pgx_scripts/tree/master/bloat&#34;&gt;pgexperts/pgx_scripts&lt;/a&gt;. Execute-os na cron job para acompanhar seu progresso semana à semana.&lt;/p&gt;

&lt;h2 id=&#34;divida-o-trabalho&#34;&gt;Divida o trabalho&lt;/h2&gt;

&lt;p&gt;Tabelas imensas tem um grande potencial para inchaço, tanto da baixa sensibilidade do fator de escala do VACUUM e geralmente devido a extensas rotatividades de registros. Divindido horizontalmente grandes tabelas em pequenas tabelas pode ser útil, especialmente se há um grande numero de workers do AutoVACUUM uma vez que cada workers pode executar uma tabela por vez. Mesmo assim, executar mais workers exigem maiores usos do &lt;code&gt;maintenance_work_mem&lt;/code&gt;. Uma solução  que, divide grandes tabelas e aumenta a capacidade de executar workers do AutoVACUUM é utilizar um banco de dados distrubuido composto por multiplos servidores PostgreSQL físicos  e tabelas fragmentadas.&lt;/p&gt;

&lt;p&gt;Não são apenas consultas de usuário que podem escalar num banco de dados distribuido, o VACUUM também. Pra ser justo, se as consultas estão escalando normalmente numa simples instância PostgreSQL e o único problema é o inchaço, mudar para um sistema distribuído é um exagero; Há outras maneiras de corrigir agressivamente o inchaço agúdo. No entanto, ter mais poder pra executar o VACUUM é um efeito colateral agradável em distribuir o banco de dados. É ainda mais fácil do que nunca distribuir um banco de dados PostgreSQL utilizando ferramentas de código aberto como a &lt;a href=&#34;https://github.com/citusdata/citus&#34;&gt;Citus Community Edition&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Outra alternativa é dar um passo a frente e esquecer das configurações do AutoVACUUM e utilizar um cluster PostgreSQL gerenciado como o &lt;a href=&#34;https://www.citusdata.com/product/cloud&#34;&gt;Citus Cloud&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Utilizando API do pgconfig.org</title>
      <link>http://swebber.me/blog/2016/11/05/utilizando-api-pgconfig-org/</link>
      <pubDate>Sat, 05 Nov 2016 16:37:32 -0200</pubDate>
      
      <guid>http://swebber.me/blog/2016/11/05/utilizando-api-pgconfig-org/</guid>
      <description>

&lt;p&gt;Já falei do &lt;a href=&#34;http://pgconfig.org&#34;&gt;pgconfig.org&lt;/a&gt; antes. Ele, até o momento, é uma ferramenta que faz sugestões de tuning do PostgreSQL. Acesse o site e mata a curiosidade de como funciona. Eu espero, fique tranquilo.&lt;/p&gt;

&lt;p&gt;Hoje eu quero comentar um pouco mais sobre como ele funciona, e explicar como você pode usar sua API nos seus projetos/scripts/coisas divertidas sem depender mais da interface web.&lt;/p&gt;

&lt;h3 id=&#34;como-funciona&#34;&gt;Como funciona&lt;/h3&gt;

&lt;p&gt;Na prática, a interface web (que agora vou chamar de &lt;code&gt;UI&lt;/code&gt;), acessa a api no endereço &lt;a href=&#34;https://api.pgconfig.org/v1/tuning/get-config&#34;&gt;&lt;code&gt;https://api.pgconfig.org/v1/tuning/get-config&lt;/code&gt;&lt;/a&gt;. Caso você queira simular a chamada, é só clicar no link que eu citei, mas já que o foco é automatizar as coisas, faça o mesmo teste como &lt;code&gt;curl&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl &#39;https://api.pgconfig.org/v1/tuning/get-config&#39;
{&amp;quot;data&amp;quot;: [{&amp;quot;category&amp;quot;: &amp;quot;memory_related&amp;quot;,&amp;quot;description&amp;quot;: &amp;quot;Memory Configuration&amp;quot;,&amp;quot;parameters&amp;quot;: [{&amp;quot;config_value&amp;quot;: &amp;quot;512MB&amp;quot;,&amp;quot;format&amp;quot;: &amp;quot;Bytes&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;shared_buffers&amp;quot;},{&amp;quot;config_value&amp;quot;: &amp;quot;2GB&amp;quot;,&amp;quot;format&amp;quot;: &amp;quot;Bytes&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;effective_cache_size&amp;quot;},{&amp;quot;config_value&amp;quot;: &amp;quot;20MB&amp;quot;,&amp;quot;format&amp;quot;: &amp;quot;Bytes&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;work_mem&amp;quot;},{&amp;quot;config_value&amp;quot;: &amp;quot;128MB&amp;quot;,&amp;quot;format&amp;quot;: &amp;quot;Bytes&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;maintenance_work_mem&amp;quot;}]},{&amp;quot;category&amp;quot;: &amp;quot;checkpoint_related&amp;quot;,&amp;quot;description&amp;quot;: &amp;quot;Checkpoint Related Configuration&amp;quot;,&amp;quot;parameters&amp;quot;: [{&amp;quot;config_value&amp;quot;: &amp;quot;512MB&amp;quot;,&amp;quot;format&amp;quot;: &amp;quot;Bytes&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;min_wal_size&amp;quot;},{&amp;quot;config_value&amp;quot;: &amp;quot;2GB&amp;quot;,&amp;quot;format&amp;quot;: &amp;quot;Bytes&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;max_wal_size&amp;quot;},{&amp;quot;config_value&amp;quot;: 0.7,&amp;quot;format&amp;quot;: &amp;quot;Float&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;checkpoint_completion_target&amp;quot;},{&amp;quot;config_value&amp;quot;: &amp;quot;15MB&amp;quot;,&amp;quot;format&amp;quot;: &amp;quot;Bytes&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;wal_buffers&amp;quot;}]},{&amp;quot;category&amp;quot;: &amp;quot;network_related&amp;quot;,&amp;quot;description&amp;quot;: &amp;quot;Network Related Configuration&amp;quot;,&amp;quot;parameters&amp;quot;: [{&amp;quot;config_value&amp;quot;: &amp;quot;*&amp;quot;,&amp;quot;format&amp;quot;: &amp;quot;String&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;listen_addresses&amp;quot;},{&amp;quot;config_value&amp;quot;: 100,&amp;quot;format&amp;quot;: &amp;quot;Decimal&amp;quot;,&amp;quot;name&amp;quot;: &amp;quot;max_connections&amp;quot;}]}],&amp;quot;jsonapi&amp;quot;: {&amp;quot;version&amp;quot;: &amp;quot;1.0&amp;quot;},&amp;quot;links&amp;quot;: {&amp;quot;self&amp;quot;: &amp;quot;http://api.pgconfig.org/v1/tuning/get-config&amp;quot;},&amp;quot;meta&amp;quot;: {&amp;quot;arguments&amp;quot;: {},&amp;quot;copyright&amp;quot;: &amp;quot;PGConfig API&amp;quot;,&amp;quot;version&amp;quot;: &amp;quot;2.0 beta&amp;quot;}}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ok, já que o &lt;code&gt;JSON+API&lt;/code&gt; que a URL retona fica um pouco dificil de ler, eu vou formatar ele pra você:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;{  
   &amp;quot;data&amp;quot;:[  
      {  
         &amp;quot;category&amp;quot;:&amp;quot;memory_related&amp;quot;,
         &amp;quot;description&amp;quot;:&amp;quot;Memory Configuration&amp;quot;,
         &amp;quot;parameters&amp;quot;:[  
            {  
               &amp;quot;config_value&amp;quot;:&amp;quot;512MB&amp;quot;,
               &amp;quot;format&amp;quot;:&amp;quot;Bytes&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;shared_buffers&amp;quot;
            },
            {  
               &amp;quot;config_value&amp;quot;:&amp;quot;2GB&amp;quot;,
               &amp;quot;format&amp;quot;:&amp;quot;Bytes&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;effective_cache_size&amp;quot;
            },
            {  
               &amp;quot;config_value&amp;quot;:&amp;quot;20MB&amp;quot;,
               &amp;quot;format&amp;quot;:&amp;quot;Bytes&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;work_mem&amp;quot;
            },
            {  
               &amp;quot;config_value&amp;quot;:&amp;quot;128MB&amp;quot;,
               &amp;quot;format&amp;quot;:&amp;quot;Bytes&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;maintenance_work_mem&amp;quot;
            }
         ]
      },
      {  
         &amp;quot;category&amp;quot;:&amp;quot;checkpoint_related&amp;quot;,
         &amp;quot;description&amp;quot;:&amp;quot;Checkpoint Related Configuration&amp;quot;,
         &amp;quot;parameters&amp;quot;:[  
            {  
               &amp;quot;config_value&amp;quot;:&amp;quot;512MB&amp;quot;,
               &amp;quot;format&amp;quot;:&amp;quot;Bytes&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;min_wal_size&amp;quot;
            },
            {  
               &amp;quot;config_value&amp;quot;:&amp;quot;2GB&amp;quot;,
               &amp;quot;format&amp;quot;:&amp;quot;Bytes&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;max_wal_size&amp;quot;
            },
            {  
               &amp;quot;config_value&amp;quot;:0.7,
               &amp;quot;format&amp;quot;:&amp;quot;Float&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;checkpoint_completion_target&amp;quot;
            },
            {  
               &amp;quot;config_value&amp;quot;:&amp;quot;15MB&amp;quot;,
               &amp;quot;format&amp;quot;:&amp;quot;Bytes&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;wal_buffers&amp;quot;
            }
         ]
      },
      {  
         &amp;quot;category&amp;quot;:&amp;quot;network_related&amp;quot;,
         &amp;quot;description&amp;quot;:&amp;quot;Network Related Configuration&amp;quot;,
         &amp;quot;parameters&amp;quot;:[  
            {  
               &amp;quot;config_value&amp;quot;:&amp;quot;*&amp;quot;,
               &amp;quot;format&amp;quot;:&amp;quot;String&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;listen_addresses&amp;quot;
            },
            {  
               &amp;quot;config_value&amp;quot;:100,
               &amp;quot;format&amp;quot;:&amp;quot;Decimal&amp;quot;,
               &amp;quot;name&amp;quot;:&amp;quot;max_connections&amp;quot;
            }
         ]
      }
   ],
   &amp;quot;jsonapi&amp;quot;:{  
      &amp;quot;version&amp;quot;:&amp;quot;1.0&amp;quot;
   },
   &amp;quot;links&amp;quot;:{  
      &amp;quot;self&amp;quot;:&amp;quot;http://api.pgconfig.org/v1/tuning/get-config&amp;quot;
   },
   &amp;quot;meta&amp;quot;:{  
      &amp;quot;arguments&amp;quot;:{  

      },
      &amp;quot;copyright&amp;quot;:&amp;quot;PGConfig API&amp;quot;,
      &amp;quot;version&amp;quot;:&amp;quot;2.0 beta&amp;quot;
   }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Basicamente, os dados importantes estão dentro de &lt;code&gt;&amp;quot;data&amp;quot;&lt;/code&gt;, aonde são agrupados por categoria, igualzinho no site. ;)&lt;/p&gt;

&lt;p&gt;Uma coisa importante sobre isso é que você pode formatar a saida apresentada de forma mais conveniente, apenas informando o parâmetro &lt;code&gt;format=conf&lt;/code&gt;, conforme o exemplo abaixo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl &#39;https://api.pgconfig.org/v1/tuning/get-config?format=conf&#39;
# Generated by PGConfig 2.0 beta
## http://pgconfig.org

# Memory Configuration
shared_buffers = 512MB
effective_cache_size = 2GB
work_mem = 20MB
maintenance_work_mem = 128MB

# Checkpoint Related Configuration
min_wal_size = 512MB
max_wal_size = 2GB
checkpoint_completion_target = 0.7
wal_buffers = 15MB

# Network Related Configuration
listen_addresses = &#39;*&#39;
max_connections = 100
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Outras opções para o &lt;code&gt;format&lt;/code&gt; são &lt;code&gt;json&lt;/code&gt;(que é a default) e &lt;code&gt;alter_system&lt;/code&gt;, veja:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl &#39;https://api.pgconfig.org/v1/tuning/get-config?format=alter_system&#39;
-- Generated by PGConfig 2.0 beta
---- http://pgconfig.org

-- Memory Configuration
ALTER SYSTEM SET shared_buffers TO &#39;512MB&#39;;
ALTER SYSTEM SET effective_cache_size TO &#39;2GB&#39;;
ALTER SYSTEM SET work_mem TO &#39;20MB&#39;;
ALTER SYSTEM SET maintenance_work_mem TO &#39;128MB&#39;;

-- Checkpoint Related Configuration
ALTER SYSTEM SET min_wal_size TO &#39;512MB&#39;;
ALTER SYSTEM SET max_wal_size TO &#39;2GB&#39;;
ALTER SYSTEM SET checkpoint_completion_target TO &#39;0.7&#39;;
ALTER SYSTEM SET wal_buffers TO &#39;15MB&#39;;

-- Network Related Configuration
ALTER SYSTEM SET listen_addresses TO &#39;*&#39;;
ALTER SYSTEM SET max_connections TO &#39;100&#39;;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pegou a idéia aqui? pra mudar a saida, tudo o que você precisa é ir informando os parâmetros na URL.&lt;/p&gt;

&lt;h3 id=&#34;parâmetros-disponíveis&#34;&gt;Parâmetros disponíveis&lt;/h3&gt;

&lt;p&gt;A relação abaixo lista os parâmetros disponíveis:&lt;/p&gt;

&lt;table class=&#34;table table-striped table-bordered&#34;&gt;
        &lt;thead&gt;
            &lt;tr&gt;
                &lt;th&gt;Parâmetro&lt;/th&gt;
                &lt;th&gt;Possíveis valores&lt;/th&gt;
                &lt;th&gt;Valor padrão&lt;/th&gt;
                &lt;th&gt;Descrição&lt;/th&gt;
            &lt;/tr&gt;
        &lt;/thead&gt;
        &lt;tbody&gt;
            &lt;tr&gt;
                &lt;td&gt;&lt;code&gt;pg_version&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;da versão &lt;code&gt;9.0&lt;/code&gt; até a &lt;code&gt;9.6&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;9.6&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;Informa a versão do PostgreSQL&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;&lt;code&gt;total_ram&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;qualquer valor acima de &lt;code&gt;1GB&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;2GB&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;Quantidade de memória &lt;strong&gt;dedicada&lt;/strong&gt; ao PostgreSQL.&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;&lt;code&gt;max_connections&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;qualquer valor acima de &lt;code&gt;1&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;100&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;Quantidade &lt;strong&gt;esperada&lt;/strong&gt; de conexões&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;&lt;code&gt;env_name&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;WEB&lt;/code&gt;, &lt;code&gt;OLTP&lt;/code&gt;, &lt;code&gt;DW&lt;/code&gt;, &lt;code&gt;Mixed&lt;/code&gt; e &lt;code&gt;Desktop&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;WEB&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;Define o ambiente que o servidor vai rodar (mais detalhes abaixo)&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;&lt;code&gt;os_type&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;Linux&lt;/code&gt;, &lt;code&gt;Windows&lt;/code&gt; e &lt;code&gt;Unix&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;Linux&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;Define o tipo do sistema operacional utilizado&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;&lt;code&gt;arch&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;x86-64&lt;/code&gt; e &lt;code&gt;i686&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;x86-64&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;Define a arquitetura do servidor&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;&lt;code&gt;format&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;json&lt;/code&gt;, &lt;code&gt;conf&lt;/code&gt; e &lt;code&gt;alter_system&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;json&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;Muda o formato de saída&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;&lt;code&gt;show_doc&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;true&lt;/code&gt; e &lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;Mostra a documentação (valido apenas pro formato &lt;code&gt;json&lt;/code&gt;)&lt;/td&gt;
            &lt;/tr&gt;
            &lt;tr&gt;
                &lt;td&gt;&lt;code&gt;include_pgbadger&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;true&lt;/code&gt; e &lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;&lt;code&gt;false&lt;/code&gt;&lt;/td&gt;
                &lt;td&gt;Adiciona as configurações para habilitar o pgbadger&lt;/td&gt;
            &lt;/tr&gt;
        &lt;/tbody&gt;
    &lt;/table&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Importante&lt;/strong&gt; Não esqueça de, ao informar o parâmetro &lt;code&gt;total_ram&lt;/code&gt;, passar o valor formatado conforme a expressão &lt;code&gt;[0-9]{1,}GB&lt;/code&gt;, por exemplo: &lt;code&gt;4GB&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;sobre-o-ambiente&#34;&gt;Sobre o ambiente&lt;/h4&gt;

&lt;p&gt;A relação abaixo explica um pouco mais sobre os ambientes:&lt;/p&gt;

&lt;table class=&#34;table table-bordered&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Nome&lt;/th&gt;
            &lt;th&gt;Descrição&lt;/th&gt;
            &lt;th&gt;Exemplos de uso&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;WEB&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Aplicações web geral&lt;/td&gt;
            &lt;td&gt;Aplicações com perfil web, como um portal ou aplicativo corporativo&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;OLTP&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Aplicações com grande volume de transações&lt;/td&gt;
            &lt;td&gt;Sistemas do tipo ERP ou grandes sistemas corporativos com muitas transações simultâneas&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;DW&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Aplicações de DataWare House&lt;/td&gt;
            &lt;td&gt;Sistemas de BI em geral&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;Mixed&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Ambientes que compartilham o banco e a aplicação no mesmo servidor&lt;/td&gt;
            &lt;td&gt;Pequenos sistemas, normalmente rodando na web&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;Desktop&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Ambiente de desenvolvimento&lt;/td&gt;
            &lt;td&gt;Máquina de desenvolvimento, suporte ou pré-vendas&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;exemplo-completo&#34;&gt;Exemplo completo&lt;/h4&gt;

&lt;p&gt;Segue abaixo um exemplo completo, igualzinho ao utilizado pela &lt;code&gt;UI&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl &#39;https://api.pgconfig.org/v1/tuning/get-config?env_name=WEB&amp;amp;format=alter_system&amp;amp;include_pgbadger=true&amp;amp;log_format=stderr&amp;amp;max_connections=100&amp;amp;pg_version=9.6&amp;amp;total_ram=2GB&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;como-são-calculadas-os-valores&#34;&gt;Como são calculadas os valores?&lt;/h3&gt;

&lt;p&gt;A fim de deixar o processo mais claro, eu criei uma entrada na API pra listar as regras. Ele pode ser acessado na URL abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://api.pgconfig.org/v1/tuning/get-rules&#34;&gt;/v1/tuning/get-rules&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Importante:&lt;/strong&gt; A chamada pra esse contexto permite filtrar &lt;code&gt;os_type&lt;/code&gt;, &lt;code&gt;arch&lt;/code&gt; e &lt;code&gt;env_name&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Os dados que contem detalhes de como cada parâmetro é caculado são &lt;code&gt;formula&lt;/code&gt; e &lt;code&gt;max_value&lt;/code&gt;, por exemplo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;...
&amp;quot;format&amp;quot;: &amp;quot;Bytes&amp;quot;,
&amp;quot;formula&amp;quot;: &amp;quot;TOTAL_RAM / 4&amp;quot;,
&amp;quot;max_value&amp;quot;: &amp;quot;2047MB&amp;quot;,
&amp;quot;name&amp;quot;: &amp;quot;shared_buffers&amp;quot;
...
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Note que os valores são influenciados pelos filtros citados acima.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;exemplo-de-chamada&#34;&gt;Exemplo de chamada&lt;/h4&gt;

&lt;p&gt;Recomendo que você abra a URL no navegador pra facilitar a visualização (ou &lt;a href=&#34;https://jsonformatter.curiousconcept.com/&#34;&gt;formate o json&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;curl &#39;https://api.pgconfig.org/v1/tuning/get-rules?os_type=Windows&amp;amp;arch=i686&amp;amp;env_name=OLTP&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;outras-opções-da-api&#34;&gt;Outras opções da API&lt;/h3&gt;

&lt;table class=&#34;table table-striped table-bordered&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Endereço&lt;/th&gt;
            &lt;th&gt;Descrição&lt;/th&gt;
            &lt;th&gt;exemplo de saída&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;a href=&#34;https://api.pgconfig.org/v1/tuning/get-config-all-environments&#34;&gt;&lt;code&gt;/v1/tuning/get-config-all-environments&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;Lista as regras pra todos os ambientes&lt;/td&gt;
            &lt;td&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&lt;/code&gt;...
&#34;data&#34;: [
    {
    &#34;configuration&#34;: [..],
    &#34;environment&#34;: &#34;WEB&#34;
    },
    {
    &#34;configuration&#34;: [..],
    &#34;environment&#34;: &#34;OLTP&#34;
    },
    {
    &#34;configuration&#34;: [..],
    &#34;environment&#34;: &#34;DW&#34;
    },
    {
    &#34;configuration&#34;: [..],
    &#34;environment&#34;: &#34;Mixed&#34;
    },
    {
    &#34;configuration&#34;: [..],
    &#34;environment&#34;: &#34;Desktop&#34;
    }
]
...&lt;/pre&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;a href=&#34;https://api.pgconfig.org/v1/tuning/list-enviroments&#34;&gt;&lt;code&gt;/v1/tuning/list-enviroments&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;Lista todos os ambientes&lt;/td&gt;
            &lt;td&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&lt;/code&gt;...
&#34;data&#34;: [
    &#34;WEB&#34;,
    &#34;OLTP&#34;,
    &#34;DW&#34;,
    &#34;Mixed&#34;,
    &#34;Desktop&#34;
],
...&lt;/pre&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;a href=&#34;https://api.pgconfig.org/v1/generators/pgbadger/get-config&#34;&gt;&lt;code&gt;/v1/generators/pgbadger/get-config&lt;/code&gt;&lt;/a&gt;&lt;/td&gt;
            &lt;td&gt;Lista as configurações do pgbadger (aceita o parametro &lt;code&gt;format&lt;/code&gt;)&lt;/td&gt;
            &lt;td&gt;&lt;pre&gt;&lt;code class=&#34;language-json&#34;&gt;&lt;/code&gt;...
&#34;data&#34;: [
    {
    &#34;category&#34;: &#34;log_config&#34;,
    &#34;description&#34;: &#34;Logging configuration for pgbadger&#34;,
    &#34;parameters&#34;: [
        {
        &#34;config_value&#34;: &#34;on&#34;,
        &#34;name&#34;: &#34;logging_collector&#34;
        },
        {
        &#34;config_value&#34;: &#34;on&#34;,
        &#34;name&#34;: &#34;log_checkpoints&#34;
        },
        {
        &#34;config_value&#34;: &#34;on&#34;,
        &#34;name&#34;: &#34;log_connections&#34;
        },
        {
        &#34;config_value&#34;: &#34;on&#34;,
        &#34;name&#34;: &#34;log_disconnections&#34;
        },
        {
        &#34;config_value&#34;: &#34;on&#34;,
        &#34;name&#34;: &#34;log_lock_waits&#34;
        },
        {
        &#34;config_value&#34;: &#34;0&#34;,
        &#34;name&#34;: &#34;log_temp_files&#34;
        },
        {
        &#34;config_value&#34;: &#34;C&#34;,
        &#34;format&#34;: &#34;String&#34;,
        &#34;name&#34;: &#34;lc_messages&#34;
        },
        {
        &#34;comment&#34;: &#34;Adjust the minimum time to collect data&#34;,
        &#34;config_value&#34;: &#34;10s&#34;,
        &#34;format&#34;: &#34;Time&#34;,
        &#34;name&#34;: &#34;log_min_duration_statement&#34;
        },
        {
        &#34;config_value&#34;: &#34;0&#34;,
        &#34;name&#34;: &#34;log_autovacuum_min_duration&#34;
        }
    ]
},
...&lt;/pre&gt;&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Outras opções estão sendo desenvolvidas e em breve vou postar mais detalhes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Checklist mensal do PostgreSQL</title>
      <link>http://swebber.me/blog/2016/02/15/checklist-mensal-do-postgresql/</link>
      <pubDate>Mon, 15 Feb 2016 16:54:52 -0200</pubDate>
      
      <guid>http://swebber.me/blog/2016/02/15/checklist-mensal-do-postgresql/</guid>
      <description>

&lt;p&gt;Este post é uma humilde adaptação de um &lt;a href=&#34;http://www.jasonstrate.com/monthly-sql-server-checklist/&#34;&gt;ótimo artigo sobre o SQL Server&lt;/a&gt;. Sim, você leu certo: Peguei umas idéias do checklist do SQL Server.&lt;/p&gt;

&lt;h2 id=&#34;1-atualize-o-so-do-seu-servidor&#34;&gt;1. Atualize o SO do seu servidor&lt;/h2&gt;

&lt;p&gt;Eu sei. Você não faz isso. Acha que não precisa, que o problema não é seu, mas nos últimos anos tivemos tantos problemas de segurança recentes (&lt;a href=&#34;http://heartbleed.com&#34;&gt;HeartBleead&lt;/a&gt;, &lt;a href=&#34;https://access.redhat.com/articles/1200223&#34;&gt;Shellshock&lt;/a&gt;, etc), que sabe-se lá o que pode nos assustar no futuro. Quer uma sugestão? Atualiza tudo, sempre [que possível].&lt;/p&gt;

&lt;h2 id=&#34;2-atualize-seu-servidor-postgresql&#34;&gt;2. Atualize seu servidor PostgreSQL&lt;/h2&gt;

&lt;p&gt;Por que? por que sim, oras. Precisa de mais motivos? Então pensa que BUGs e falhas de segurança são corrigidos o quanto antes.&lt;/p&gt;

&lt;p&gt;Sua versão instalada não tem mais atualizações ou não é mais suportada? Para tudo e bora atualizar. Não só pela segurança, mas toda versão tem muita coisa bacana, aposto que os desenvolvedores implorariam pra você atualizar. Vai lá e mostra o release notes pros caras, depois vem e me agradece. :P&lt;/p&gt;

&lt;p&gt;Não acredita? Abre aí então:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://wiki.postgresql.org/wiki/What&#39;s_new_in_PostgreSQL_9.5&#34;&gt;&lt;code&gt;https://wiki.postgresql.org/wiki/What&#39;s_new_in_PostgreSQL_9.5&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Pra te dar uma dica de como atualizar, sempre dê uma lida no release notes. Lá tem tudo o que nós, meros mortais (&lt;em&gt;ou não devs&lt;/em&gt;), precisavamos saber pra atualizar o banco. Normalmente é bem simples (para o banco, atualiza os binários, sobe o banco), e caso seja mais elaborado, vai estar la no release notes, bem bonitinho.&lt;/p&gt;

&lt;p&gt;Quer saber das versões novas e tem preguiça de ver o site toda hora? Então assine o &lt;a href=&#34;http://www.postgresql.org/versions.rss&#34;&gt;feed RSS&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ainda assim da muito trabalho? Então utilize os repositórios do PGDG, que tem pra varios sabores (&lt;a href=&#34;https://wiki.postgresql.org/wiki/Apt&#34;&gt;APT&lt;/a&gt; e &lt;a href=&#34;https://wiki.postgresql.org/wiki/RPM_Installation&#34;&gt;YUM&lt;/a&gt;  por exemplo).&lt;/p&gt;

&lt;h2 id=&#34;3-valide-suas-rotinas-de-backup&#34;&gt;3. Valide suas rotinas de backup&lt;/h2&gt;

&lt;p&gt;Verifique todo seu processo de backup. Messa os tempos de execução, documente cada etapa do processo e tente deixar ele o mais simples possível. Pontos importantes a validar são: &lt;em&gt;Tamanho ocupado&lt;/em&gt;, &lt;em&gt;duração&lt;/em&gt;, &lt;em&gt;falhas na execução&lt;/em&gt; e &lt;em&gt;monitoramento do mesmo&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Já que estamos falando de backup, faça a lição de casa e avalie as soluções de backup mais populares:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.postgresql.org/docs/current/static/backup.html&#34;&gt;DOC Oficial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pgbarman.org&#34;&gt;pgbarman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/michaelpq/pg_arman&#34;&gt;pg_arman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.depesz.com/2013/09/11/how-to-make-backups-of-postgresql/&#34;&gt;scripts customizados do @depesz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Já que você faz backup do seu banco, não esqueça de fazer backup das suas configurações. Afinal, nunca se sabe quando vamos precisar fazer um &lt;code&gt;Disaster Recovery&lt;/code&gt;. Falando nisso, é uma boa planejar uma solução de &lt;code&gt;HA&lt;/code&gt;, não é mesmo?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Se você ainda usa o &lt;code&gt;pg_dump&lt;/code&gt; como sua principal solução de backup, dá uma olhada nesse &lt;a href=&#34;http://savepoint.blog.br/dump-nao-e-backup/&#34;&gt;artigo bacana do @telles&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;4-teste-com-vontade-a-sua-rotina-de-restore&#34;&gt;4. Teste, &lt;em&gt;com vontade&lt;/em&gt;, a sua rotina de restore&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Backup bom é o que restaura.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Eu nunca canso de dizer isso!&lt;/p&gt;

&lt;p&gt;Já que seu backup está rodando certinho, faça um restore dos dados. Meça os tempos, documente o processo. Se tiver como fazer isso num servidor novo, melhor aínda! O importante é ficar tranquilo e ter tudo sob controle quando a casa cair e ele for realmente necessário.&lt;/p&gt;

&lt;h2 id=&#34;5-verifique-o-desempenho-e-a-saude-do-seu-banco&#34;&gt;5. Verifique o desempenho e a saude do seu banco&lt;/h2&gt;

&lt;p&gt;Deixe de sofrer. Há muitas soluções de monitoramento no mercado (&lt;a href=&#34;http://www.zabbix.com&#34;&gt;zabbix&lt;/a&gt;, &lt;a href=&#34;https://www.nagios.org/&#34;&gt;Nagios&lt;/a&gt;, etc). Coloque ele pra funcionar e monitorar detalhes uteis do SO e também do servidor PostgreSQL. Ajuste seu log para um formato de leitura mais eficiente (como o CSV, por exemplo) e gere reports do &lt;a href=&#34;http://dalibo.github.io/pgbadger/&#34;&gt;pgbadger&lt;/a&gt; ou &lt;a href=&#34;https://prezi.com/f2dvt6m9tbf9/integrating-postgresql-with-logstash-for-real-time-monitoring/&#34;&gt;uma solução mais elaborada&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Caso você use a versão 9.3 ou superior, você &lt;strong&gt;DEVE&lt;/strong&gt; dar uma olhada no &lt;a href=&#34;http://dalibo.github.io/powa/&#34;&gt;PoWA&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;6-revise-seu-tuning-no-so-e-no-postgresql-conf&#34;&gt;6. Revise seu tuning no SO e no &lt;code&gt;postgresql.conf&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Agora que você passou a monitorar o banco, aproveita o embalo e começa a dar uma revisada no tuning do sistema operacional, começando pelo &lt;code&gt;/etc/sysctl.conf&lt;/code&gt;. Infelizmente, cada evento pode apontar um arquivo de configuração diferente. O jeito fácil é entender o que está rolando no servidor e ver se isso tu trata num dos &lt;strong&gt;3 pilares&lt;/strong&gt;: &lt;em&gt;Hardware&lt;/em&gt;, &lt;em&gt;Sistema Operacional&lt;/em&gt; e &lt;em&gt;Banco de dados&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;SO revisado? Então manda ver e da uma olhada configurações do &lt;code&gt;postgresql.conf&lt;/code&gt;. Se você nunca fez isso, eu sugiro que dê uma olhada no &lt;a href=&#34;http://pgconfig.org&#34;&gt;PGConfig&lt;/a&gt;. Lá é um bom lugar pra começar.&lt;/p&gt;

&lt;p&gt;Não esqueça do hardware. As vezes não tem jeito, precisamos de um upgrade. :D&lt;/p&gt;

&lt;h2 id=&#34;7-analise-e-ajuste-o-baseline&#34;&gt;7. Analise e ajuste o baseline&lt;/h2&gt;

&lt;p&gt;Chegou a conclusão que precisa de algum ajuste no tuning? O que mudou? Aumentou a quantidade de usuários? Nova feature baseado em &lt;a href=&#34;http://desciclopedia.org/wiki/Gambi_Design_Patterns&#34;&gt;boas praticas do mercado&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;Será que é realmente necessário esse ajuste?&lt;/p&gt;

&lt;h2 id=&#34;8-valide-o-seu-capacity-plan-https-en-wikipedia-org-wiki-capacity-planning&#34;&gt;8. Valide o seu &lt;a href=&#34;https://en.wikipedia.org/wiki/Capacity_planning&#34;&gt;Capacity Plan&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Se você tem um em ação, será que o mesmo está adequado? Se você fez algum ajuste sugerido acima, será que o mesmo não precisa de nenhum ajuste? Talvez seja o momento de mudar algumas projeções.&lt;/p&gt;

&lt;h2 id=&#34;9-sumarize-e-monte-um-plano&#34;&gt;9. Sumarize e monte um plano&lt;/h2&gt;

&lt;p&gt;Avaliou tudo o que precisa mudar? Agora monte o seu proprio plano de ação, alinhe com a equipe e batalhe pelas janelas de manutenção.&lt;/p&gt;

&lt;p&gt;Depois de tudo pronto e configurado, mande o seu próprio release notes pro pessoal do marketing e deixe eles fazerem propaganda da saude do seu banco! :P&lt;/p&gt;

&lt;h2 id=&#34;faltou-algo&#34;&gt;Faltou algo?&lt;/h2&gt;

&lt;p&gt;Certamente algo importante pode ter ficado pra trás. Deixa um comentário pra gente ajustar assim que der. :D&lt;/p&gt;

&lt;p&gt;[]&amp;rsquo;s&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Desafio sobre a replicação do PostgreSQL!</title>
      <link>http://swebber.me/blog/2016/01/21/desafio-sobre-a-replicao-do-postgresql/</link>
      <pubDate>Thu, 21 Jan 2016 20:05:03 -0200</pubDate>
      
      <guid>http://swebber.me/blog/2016/01/21/desafio-sobre-a-replicao-do-postgresql/</guid>
      <description>

&lt;p&gt;Esse ano, &lt;a href=&#34;http://savepoint.blog.br/10-anos-de-pgbr/&#34;&gt;segundo fontes confiáveis&lt;/a&gt;, é aniversário da Comunidade Brasileira de PostgreSQL. E pra fazer a minha parte (e tirar a poeira do blog) eu lanço um desafio público: falar sobre a replicação do PostgreSQL. E isso não é pouca coisa!&lt;/p&gt;

&lt;p&gt;Até o momento, essas são as soluções mais populares:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Replicação Nativa: &lt;a href=&#34;http://www.postgresql.org/docs/current/static/warm-standby.html#STREAMING-REPLICATION&#34;&gt;Streaming Replication&lt;/a&gt; e &lt;a href=&#34;http://www.postgresql.org/docs/current/static/warm-standby.html#STREAMING-REPLICATION-SLOTS&#34;&gt;Replication Slots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://2ndquadrant.com/en-us/resources/bdr/&#34;&gt;BDR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://2ndquadrant.com/en/resources/pglogical/&#34;&gt;PGLogical&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://slony.info/&#34;&gt;Slony&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.postgresql.org/wiki/SkyTools#Londiste&#34;&gt;Londiste&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bucardo.org/wiki/Bucardo&#34;&gt;Bucardo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.keithf4.com/mimeo-introduction/&#34;&gt;Mimeo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pgpool.net/mediawiki/index.php/Main_Page&#34;&gt;PGpool II&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.repmgr.org/&#34;&gt;REPMgr&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;a-proposta&#34;&gt;A proposta&lt;/h2&gt;

&lt;p&gt;A idéia é fazer um ambiente de testes utilizando a versão mais recente do banco e da solução cobrindo os pontos abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Instalação e configuração&lt;/li&gt;
&lt;li&gt;Operação basica para replicar dados ou conjunto de dados&lt;/li&gt;
&lt;li&gt;Procedimentos que previnem tolerancia a falhas&lt;/li&gt;
&lt;li&gt;Validar meios para replicar dados distribuidos geograficamente&lt;/li&gt;
&lt;li&gt;Medição dos tempos de carga intensa (como o restore do banco) e moderado (como a atualização de dados e tudo mais)&lt;/li&gt;
&lt;li&gt;Avaliação de pontos fortes e fracos&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;sobre-o-ambiente-de-testes&#34;&gt;Sobre o ambiente de testes&lt;/h2&gt;

&lt;h3 id=&#34;quanto-a-máquina-virtual-dos-testes&#34;&gt;Quanto a máquina virtual dos testes&lt;/h3&gt;

&lt;p&gt;Pra simplificar o processo de setup do lab, eu criei uma configuração do &lt;a href=&#34;https://www.vagrantup.com/&#34;&gt;Vagrant&lt;/a&gt; composta de duas máquinas virtuais na configuração abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2GB de RAM&lt;/li&gt;
&lt;li&gt;35GB espaço em disco&lt;/li&gt;
&lt;li&gt;CEntOS 7 64 Bits&lt;/li&gt;
&lt;li&gt;Repositórios configurados: epel, pgdg94 e pgdg95&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Detalhes da configuração de rede:&lt;/p&gt;

&lt;table class=&#34;table&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Hostname&lt;/th&gt;
            &lt;th&gt;IP&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;master&lt;/td&gt;
            &lt;td&gt;192.168.100.100&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;slave&lt;/td&gt;
            &lt;td&gt;192.168.100.200&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Abaixo segue o Vagrantfile:
&lt;script src=&#34;//gist.github.com/sebastianwebber/d49ac8507d48c9cfdc4f.js?file=Vagrantfile&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Para utiliza-lo, execute:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/sebastianwebber/d49ac8507d48c9cfdc4f.js?file=setup.sh&#34;&gt;&lt;/script&gt;

&lt;h3 id=&#34;quanto-a-base-de-dados&#34;&gt;Quanto a base de dados&lt;/h3&gt;

&lt;p&gt;A base de testes adotada é o banco do &lt;a href=&#34;http://www.imdb.com/&#34;&gt;IMDB&lt;/a&gt;. Pra simplificar o processo de importação e teste eu já deixei um dump prontinho na URL abaixo:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://1drv.ms/1TjlPXl&#34;&gt;&lt;code&gt;http://1drv.ms/1TjlPXl&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Detalhes pra importação do dump são os de sempre:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;createdb -U postgres imdb
pg_restore -U postgres -d imdb -Fc --disable-triggers imdb.dump -j 4
vacuumdb -U postgres -d imdb -z
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Na sequência já publico detalhes de como popular e alterar os dados.&lt;/p&gt;

&lt;p&gt;E aí, vai encarar?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>PGConfig agora tem um dominio próprio!</title>
      <link>http://swebber.me/blog/2015/02/23/pgconfig-agora-tem-um-dominio-proprio/</link>
      <pubDate>Mon, 23 Feb 2015 09:31:40 -0300</pubDate>
      
      <guid>http://swebber.me/blog/2015/02/23/pgconfig-agora-tem-um-dominio-proprio/</guid>
      <description>&lt;p&gt;Depois de umas noites trabalhando no projeto do &lt;a href=&#34;http://pgconfig.org&#34;&gt;PGConfig&lt;/a&gt;, eu decidi registrar um dominio para facilitar o acesso ao mesmo e aí isso acabou mudando a URL de acesso do mesmo. Agora ficou &lt;a href=&#34;http://pgconfig.org&#34;&gt;http://pgconfig.org&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Pra quem interessar, o mesmo está hospedado na infraestrutura do &lt;a href=&#34;http://openshift.com&#34;&gt;OpenShift&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Sugestões são bem vindas! =)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Instalando o PL/Debugger no PostgreSQL 9.3 no EL6</title>
      <link>http://swebber.me/blog/2014/06/18/instalando-o-pl-slash-debugger-no-postgresql-93-no-el6/</link>
      <pubDate>Wed, 18 Jun 2014 11:41:06 -0300</pubDate>
      
      <guid>http://swebber.me/blog/2014/06/18/instalando-o-pl-slash-debugger-no-postgresql-93-no-el6/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;NOTA:&lt;/strong&gt; Baseado na dica do @FabrizioMello, ajustei este post e ainda deixei o processo ainda mais simples.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Com o banco já instalado via RPM, é necessário instalar algumas bibliotecas para compilar a extensão, assim instale os RPMs necessários:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yum install make gcc zlib-devel readline-devel postgresql93-devel openssl-devel git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora, faça um clone do módulo pldebbuger:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git clone http://git.postgresql.org/git/pldebugger.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para compilar o módulo, ajustar o PATH também a variável USE_PGXS:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export PATH=${PATH}:/usr/pgsql-9.3/bin
export USE_PGXS=1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora, compile e instale o módulo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd pldebugger
make
make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Configure o PostgreSQL para utilizar o módulo compilado, ajustando o arquivo &lt;code&gt;/var/lib/pgsql-9.3/data/postgresql.conf&lt;/code&gt;, descomentando a variavel &lt;code&gt;shared_preload_libraries&lt;/code&gt; e configurando-a conforme abaixo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;shared_preload_libraries = &#39;/usr/pgsql-9.3/lib/plugin_debugger.so&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Reinicie o banco de dados:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;service postgresql-9.3 restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para finalizar, crie a extensão no banco necessário para fazer o debug:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE EXTENSION pldbgapi;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>pgconfig</title>
      <link>http://swebber.me/blog/2014/05/30/pgconfig/</link>
      <pubDate>Fri, 30 May 2014 08:32:53 -0300</pubDate>
      
      <guid>http://swebber.me/blog/2014/05/30/pgconfig/</guid>
      <description>&lt;p&gt;Baseado na idéia da &lt;a href=&#34;http://lbconfig.appspot.com/&#34;&gt;ferramenta de configuração de Load Balancers da Redhat&lt;/a&gt;, criei uma página no mesmo formato, mas com a finalidade de fazer o tunning inicial do servidor PostgreSQL. Apesar de conhecer o &lt;a href=&#34;https://github.com/gregs1104/pgtune&#34;&gt;pgtune&lt;/a&gt;, achei que o formato web seria mais atrativo e tive ele como base em alguns parâmetros.&lt;/p&gt;

&lt;p&gt;A versão inicial do mesmo cobre apenas alguns parâmetros básicos de memória, mas vou expandindo isso com o tempo. Pretendo nela cobrir alguns aspectos do SO também.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://swebber.me/wp-content/uploads/2014/05/30/pgconfig.png&#34; alt=&#34;PGConfig screenshot&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;del&gt;Para acessa-lá, utilize a url: &lt;a href=&#34;http://swebber.me/pgconfig/&#34;&gt;http://swebber.me/pgconfig/&lt;/a&gt;&lt;/del&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Novo endereço disponível!&lt;/strong&gt; Acesse: &lt;a href=&#34;http://pgconfig.org&#34;&gt;http://pgconfig.org&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Se tiver afim de me ajudar, dá uma olhada no &lt;a href=&#34;https://github.com/sebastianwebber/pgconfig&#34;&gt;repositório do projeto no github&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;del&gt;PS: ainda não criei um repositório no github para o projeto, mas logo-logo, eu faço isso.&lt;/del&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Trabalhando com o londiste</title>
      <link>http://swebber.me/blog/2014/04/25/trabalhando-com-o-londiste/</link>
      <pubDate>Fri, 25 Apr 2014 14:33:00 -0300</pubDate>
      
      <guid>http://swebber.me/blog/2014/04/25/trabalhando-com-o-londiste/</guid>
      <description>

&lt;p&gt;Este post é um complemento para o post que cita a instalação e configuração do Londiste. Vou atualizar este post conforme possível.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;É importante lembrar que a citação &lt;code&gt;[CON_STR]&lt;/code&gt; quer dizer a string de conexão utilizada, seguindo o padrão utilizado pela libpq.&lt;/p&gt;

&lt;p&gt;Para simplificar a configuração, ao citar o arquivo de configuração, vou sempre utilizar o arquivo &lt;code&gt;/etc/londiste/config.ini&lt;/code&gt;, mas lembre é necessário criar um arquivo separado para cada job.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;string-de-conexão&#34;&gt;String de conexão&lt;/h2&gt;

&lt;p&gt;A string de conexão é detalhada na documentação oficial, conforme abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Sintaxe:&lt;/strong&gt; &lt;a href=&#34;http://www.postgresql.org/docs/9.2/static/libpq-connect.html#LIBPQ-CONNSTRING&#34;&gt;http://www.postgresql.org/docs/9.2/static/libpq-connect.html#LIBPQ-CONNSTRING&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Opções:&lt;/strong&gt; &lt;a href=&#34;http://www.postgresql.org/docs/9.2/static/libpq-connect.html#LIBPQ-PARAMKEYWORDS&#34;&gt;http://www.postgresql.org/docs/9.2/static/libpq-connect.html#LIBPQ-PARAMKEYWORDS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Exemplo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;host=localhost port=5432 dbname=mydb connect_timeout=10
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;manutenção-dos-nós&#34;&gt;Manutenção dos nós&lt;/h2&gt;

&lt;h3 id=&#34;adicionando-e-removendo-nós&#34;&gt;Adicionando e removendo nós&lt;/h3&gt;

&lt;p&gt;Para adicionar o nó tipo &lt;code&gt;root&lt;/code&gt; (master da replicação):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini create-root nome_node &amp;quot;[CON_STR]&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para adicionar nós tipo &lt;code&gt;branch&lt;/code&gt; ou &lt;code&gt;leaf&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini create-XXXXX nome_node &amp;quot;[CON_STR_DESTINO]&amp;quot; --provider=&amp;quot;[CON_STR_ROOT]&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Aonde &lt;code&gt;XXXXX&lt;/code&gt; é o tipo de nó (branch ou leaf)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[CON_STR_DESTINO]&lt;/code&gt; é a string de conexão do servidor que será o nó (slave)&lt;/p&gt;

&lt;p&gt;&lt;code&gt;[CON_STR_ROOT]&lt;/code&gt; é a string de conexão do servidor que será o root (master)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Para remover o nó:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini drop-node nome_node
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;iniciando-e-parando-o-daemon&#34;&gt;Iniciando e parando o daemon&lt;/h3&gt;

&lt;p&gt;Para iniciar:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini -d worker
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para parar:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini --stop
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Para forçar a parada do mesmo, substitua o &lt;code&gt;\-\-stop&lt;/code&gt; por &lt;code&gt;\-\-kill&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;trabalhando-com-tabelas&#34;&gt;Trabalhando com tabelas&lt;/h2&gt;

&lt;p&gt;Cada operação é específica para cada nó.&lt;/p&gt;

&lt;h3 id=&#34;adicionando-e-removendo-tabelas&#34;&gt;Adicionando e removendo tabelas&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;a opção &lt;code&gt;\-\-all&lt;/code&gt; pode ser utilizada para aplicar a operação em todos os objetos&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Para adicionar:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini add-table nome_tabela
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para remover:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini remove-table nome_tabela
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;listando-objetos-replicadas&#34;&gt;Listando objetos replicadas&lt;/h3&gt;

&lt;p&gt;Para listar as tabelas:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini tables
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para listar as sequências:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini seqs
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;listando-objetos-disponíveis-para-replicação&#34;&gt;Listando objetos disponíveis para replicação&lt;/h3&gt;

&lt;p&gt;O comando a baixo necessáriamente precisa ser executado em um nó slave (leaf ou branch).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini missing
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;listando-status-da-replicação&#34;&gt;Listando status da replicação&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/config.ini status
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Utilizando o Londiste 3 com o PostgreSQL 8.4</title>
      <link>http://swebber.me/blog/2014/04/24/utilizando-o-londiste-3-com-o-postgresql-8-dot-4/</link>
      <pubDate>Thu, 24 Apr 2014 18:34:52 -0300</pubDate>
      
      <guid>http://swebber.me/blog/2014/04/24/utilizando-o-londiste-3-com-o-postgresql-8-dot-4/</guid>
      <description>&lt;p&gt;Devido ao pacote do skytools não estar disponível no repositório oficial do pgdg, é necessário compilar o mesmo.&lt;/p&gt;

&lt;p&gt;Instale os pacotes necessários:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yum install gcc make libtool git python-devel python-psycopg2 asciidoc xmlto cpp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Baixe o skytools do git e instale-o:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir /opt/resources
git clone https://github.com/markokr/skytools.git /opt/resources/skytools
cd /opt/resources/skytools/
git submodule init
git submodule update
./autogen.sh
./configure --prefix=/usr/local/skytools
make
make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Referências:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/markokr/skytools/blob/master/INSTALL&#34;&gt;https://github.com/markokr/skytools/blob/master/INSTALL&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Replicação lógica com o Londiste</title>
      <link>http://swebber.me/blog/2014/04/18/replicacao-logica-com-o-londiste/</link>
      <pubDate>Fri, 18 Apr 2014 18:38:04 -0300</pubDate>
      
      <guid>http://swebber.me/blog/2014/04/18/replicacao-logica-com-o-londiste/</guid>
      <description>

&lt;p&gt;O objetivo desse post é implementar o londiste, que é uma ferramenta de replicação assincrona do tipo master/slave e faz parte do pacote de ferramentas SkyTools.&lt;/p&gt;

&lt;p&gt;Pontos a validar dessa solução:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Tempo de replicação dos dados&lt;/li&gt;
&lt;li&gt;Tipos de dados suportados, em especial:

&lt;ul&gt;
&lt;li&gt;Sequence&lt;/li&gt;
&lt;li&gt;Timestamp&lt;/li&gt;
&lt;li&gt;Bytea&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;sobre-o-ambiente-de-testes&#34;&gt;Sobre o ambiente de testes&lt;/h2&gt;

&lt;p&gt;O ambiente de testes é composto por 2 servidores linux conforme abaixo:&lt;/p&gt;

&lt;table class=&#34;table&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
          &lt;th&gt;&lt;/th&gt;
        &lt;th&gt;Master&lt;/th&gt;
        &lt;th&gt;Slave&lt;/th&gt;
        &lt;/tr&gt;
      &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;Hostname&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;pg-master&lt;/td&gt;
            &lt;td&gt;pg-slave&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;SO&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;CEntOS 6.5&lt;/td&gt;
            &lt;td&gt;CEntOS 6.5&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;PostgreSQL&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;9.3.4&lt;/td&gt;
            &lt;td&gt;9.3.4&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;Skytools&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;3.1.5&lt;/td&gt;
            &lt;td&gt;3.1.5&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;IP&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;192.168.152.149&lt;/td&gt;
            &lt;td&gt;192.168.152.150&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;instalação-do-postgresql&#34;&gt;Instalação do PostgreSQL&lt;/h2&gt;

&lt;p&gt;Processo necessário em ambos os servidores.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /tmp
wget -c http://yum.postgresql.org/9.3/redhat/rhel-6-x86_64/pgdg-centos93-9.3-1.noarch.rpm
yum localinstall pgdg-centos93-9.3-1.noarch.rpm
yum install postgresql93-server postgresql93-contrib
service postgresql-9.3 initdb
chkconfig postgresql-9.3 on
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ajustes-no-firewall&#34;&gt;Ajustes no firewall&lt;/h3&gt;

&lt;p&gt;Executar apenas no servidor master:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;iptables -I INPUT -p tcp --dport 5432 -s 192.168.152.149 -j ACCEPT
service iptables save
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Nesse lab não foi necessário parar ou ajustar o SELinux.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;ajustes-no-postgresql-conf&#34;&gt;Ajustes no postgresql.conf&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;listen_addresses = &#39;*&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ajustes-na-configuração-do-pg-hba-conf&#34;&gt;Ajustes na configuração do pg_hba.conf&lt;/h3&gt;

&lt;p&gt;Por questão de conveniência, libere acesso a todos os bancos dos servidores citados:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;host    all   postgres    192.168.152.149/32  trust
host    all   postgres    192.168.152.150/32  trust
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora inicie o postgresql:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;service postgresql-9.3 start
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;sobre-o-londiste&#34;&gt;Sobre o Londiste&lt;/h2&gt;

&lt;p&gt;O Londiste é uma ferramenta escrita em python, que utiliza o PgQ para o gerenciamento de eventos.&lt;/p&gt;

&lt;p&gt;O PgQ que é um sistema de filas escrito em PL/pgSQL. Ele é divido em 3 principais funcionalidades:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Producers:&lt;/strong&gt; coloca eventos em uma determinada fila&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ticker:&lt;/strong&gt; é um daemon que separa as filas em pacotes de eventos&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consumers:&lt;/strong&gt; lê eventos de uma determinada fila&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Quanto à replicação do londiste, a mesma é controlada pelos nós (nodes), que são classicados como:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;b&gt;root:&lt;/b&gt; é o servidor master da replicação&lt;/li&gt;
&lt;li&gt;&lt;b&gt;branch:&lt;/b&gt; é o servidor slave da replicação e permite que outros nós o utilizem para replica de dados em cascata&lt;/li&gt;
&lt;li&gt;&lt;b&gt;leaf:&lt;/b&gt; é o servidor slave da replicação e não permite replicação apartir dele&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Na prática, cada configuração do nó é um job para processar as filas do PgQ. Para manter as filas atualizadas, um daemon chamado de worker é executado. Varios workers podem ser executados simulâneamente.&lt;/p&gt;

&lt;p&gt;O daemon do PgQ, diferente do worker, precisa ter acesso a todos os bancos, para procupar pelos jobs e manter as filas e é por isso que sua string de conexão é parcial (parâmetro &lt;code&gt;base_connstr&lt;/code&gt;). Seu acesso padrão é realizado ao banco &lt;code&gt;template1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Recomendo que o daemon do PgQ seja executado do servidor que for o nó root (master) mas nada impede de o mesmo ficar em um servidor isolado.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;É importante lembrar que a solução do Londiste é implementada através de triggers nas tabelas replicadas e isso gera 2 ações necessárias: obrigatoriedade de mesma estrutura de tabelas/colunas e criação de constraints tipo PK e FK nos objetos replicados.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;instalação-do-londiste&#34;&gt;Instalação do Londiste&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yum install skytools-93 skytools-93-modules
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Talvez seja necessário reiniciar o postgresql nesse ponto.&lt;/p&gt;

&lt;h2 id=&#34;configuração-do-londiste&#34;&gt;Configuração do londiste&lt;/h2&gt;

&lt;p&gt;Crie a estrutura de dados em ambos os servidores:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;psql -U postgres -f schema_londiste.sql
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;-- criação do banco de dados
CREATE DATABASE teste_replica;

\c teste_replica

-- estrutura de dados
CREATE TABLE pessoa (
    id SERIAL PRIMARY KEY,
    nome TEXT NOT NULL,
    data_nascimento DATE NOT NULL,
    ultima_visita TIMESTAMP NOT NULL DEFAULT now(),
    foto BYTEA,
    biografia TEXT
);

-- funções de apoio
CREATE OR REPLACE FUNCTION bytea_import(p_path text, p_result out bytea) 
                   LANGUAGE plpgsql as $$
DECLARE
  l_oid oid;
  r record;
BEGIN
  p_result := &#39;&#39;;
  select lo_import(p_path) into l_oid;
  for r in ( select data 
             from pg_largeobject 
             where loid = l_oid 
             order by pageno ) loop
    p_result = p_result || r.data;
  end loop;
  perform lo_unlink(l_oid);
END;
$$;
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;servidor-master&#34;&gt;Servidor master&lt;/h3&gt;

&lt;p&gt;Crie os diretórios necessários:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;mkdir {/etc,/var/log,/var/run}/londiste
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Crie o arquivo &lt;code&gt;/etc/londiste/teste_replica_root.ini&lt;/code&gt;, com o conteúdo abaixo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[londiste3]
job_name = teste_replica_root
db = dbname=teste_replica host=192.168.152.149 user=postgres
queue_name = q_teste_replica
logfile = /var/log/londiste/teste_replica_root.log
pidfile = /var/run/londiste/teste_replica_root.pid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Quanto aos parâmetros utilizados:&lt;/p&gt;

&lt;table class=&#34;table table-bordered&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Propriedade&lt;/th&gt;
            &lt;th&gt;Descrição&lt;/th&gt;
            &lt;th&gt;Sugestão de valores&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;job_name&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;Nome do Job a ser executado&lt;/td&gt;
            &lt;td&gt;&lt;pre&gt;[NOME_BANCO]_[TIPO_NODE]&lt;/pre&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;db&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;Connection String com detalhes de conexão do banco replicado&lt;/td&gt;
            &lt;td&gt;&lt;pre&gt;host=[PGHOST] port=[PGPORT] dbname=[NOME_BANCO] user=[PGUSER]&lt;/pre&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;queue_name&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;Nome da fila&lt;/td&gt;
            &lt;td&gt;&lt;pre&gt;q_[NOME_BANCO]&lt;/pre&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;logfile&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;Caminho completo do arquivo de log&lt;/td&gt;
            &lt;td&gt;&lt;pre&gt;/var/log/londiste/[NOME_BANCO]_[TIPO_NODE].log&lt;/pre&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;b&gt;pidfile&lt;/b&gt;&lt;/td&gt;
            &lt;td&gt;Caminho completo do arquivo pid do worker&lt;/td&gt;
            &lt;td&gt;&lt;pre&gt;/var/run/londiste/[NOME_BANCO]_[TIPO_NODE].pid&lt;/pre&gt;&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
&lt;p&gt;Caso seja necessário um arquivo de exemplo para ajudar a criar as configurações do job, utilize o comando &lt;code&gt;londiste3 \-\-ini&lt;/code&gt; para gerar um arquivo de exemplo sanar as possíveis dúvidas ou ver as configurações disponíveis.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Após o ajuste das configurações é necessário criar o nó do londiste dentro do banco a ser replicado, assim, execute o comando abaixo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/teste_replica_root.ini create-root node1 &amp;quot;dbname=teste_replica host=192.168.152.149 user=postgres&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inicie o daemon para o nó criado:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 -d /etc/londiste/teste_replica_root.ini worker
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;É importante lembrar que para cada novo job é necessário criar um novo arquivo de configuração e a inicialização do job no banco replicado, conforme detalhado acima.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;configure-o-daemon-do-pgq&#34;&gt;Configure o daemon do PgQ&lt;/h4&gt;

&lt;p&gt;Crie o arquivo &lt;code&gt;/etc/londiste/pgqd.ini&lt;/code&gt;, com o conteúdo abaixo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[pgqd]
base_connstr = host=192.168.152.149 user=postgres
logfile = /var/log/londiste/pgqd.log
pidfile = /var/run/londiste/pgqd.pid
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Caso seja necessário um arquivo de exemplo para ajudar a criar as configurações do daemon, utilize o comando &lt;code&gt;pgqd \-\-ini&lt;/code&gt; para gerar um arquivo de exemplo sanar as possíveis dúvidas ou ver as configurações disponíveis.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Inicie o daemon do PgQ:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;pgqd /etc/londiste/pgqd.ini -d
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;servidor-slave&#34;&gt;Servidor slave&lt;/h3&gt;

&lt;p&gt;Crie o arquivo &lt;code&gt;/etc/londiste/teste_replica_leaf.ini&lt;/code&gt;, com o conteúdo abaixo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[londiste3]
job_name = teste_replica_leaf
db = dbname=teste_replica host=192.168.152.150 user=postgres
queue_name = q_teste_replica
logfile = /var/log/londiste/teste_replica_leaf.log
pidfile = /var/run/londiste/teste_replica_leaf.pid
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Crie o nó do londiste:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/teste_replica_leaf.ini create-leaf node2 &amp;quot;dbname=teste_replica host=192.168.152.150 user=postgres&amp;quot; --provider=&amp;quot;dbname=teste_replica host=192.168.152.149 user=postgres&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inicie o worker:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 -d /etc/londiste/teste_replica_leaf.ini worker
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;criando-a-carga-de-dados-no-servidor-master&#34;&gt;Criando a carga de dados no servidor master&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Note que não é necessário que as tabelas tenham os mesmos dados para iniciar a replicação, apenas a mesma estrutura.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Copiando os arquivos necessários para o servidor:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;scp /Users/seba/Desktop/28337_1323532011934_4739236_n.jpg root@192.168.152.149:/tmp
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ajustando as permissões:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;chown postgres:postgres /tmp/28337_1323532011934_4739236_n.jpg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Execute a carga inicial:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;psql -U postgres -d teste_replica -f carga_inicial_londiste.sql 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;
\c teste_replica

-- carga de dados
INSERT INTO pessoa (nome, data_nascimento, foto, biografia)
WITH config AS (
    SELECT 
      1000 AS max_size
)
SELECT
  &#39;Pessoa &#39; || new_id::text as nome,
  (&#39;1987-04-16&#39;::DATE + (round(CAST (random()*config.max_size AS NUMERIC),0)::TEXT || &#39; days&#39;)::INTERVAL)::DATE as data_nascimento,
  bytea_import(&#39;/tmp/28337_1323532011934_4739236_n.jpg&#39;) as foto,
  &#39;Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis tristique quam erat, in pellentesque diam feugiat in. In hac habitasse platea dictumst. Mauris malesuada faucibus diam, in tristique arcu dapibus at. Phasellus commodo nulla et orci adipiscing, quis iaculis turpis tincidunt. Proin placerat nisl non molestie porttitor. Curabitur scelerisque libero in lorem consequat consectetur ac a massa. Cras volutpat est ac lacinia ultricies. Donec quis faucibus ligula. Morbi luctus cursus lacus, a fermentum odio dignissim non. Mauris a tellus adipiscing, sodales magna sed, vehicula justo. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Nulla facilisi. Etiam eu augue nec lectus tristique bibendum vitae nec elit. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.&#39; as biografia
FROM
  config,
  generate_series(1,config.max_size) as new_id;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;adicione-as-tabelas-a-serem-replicadas&#34;&gt;Adicione as tabelas a serem replicadas&lt;/h2&gt;

&lt;h3 id=&#34;no-servidor-master&#34;&gt;No servidor master&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/teste_replica_root.ini add-table pessoa
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;no-servidor-slave&#34;&gt;No servidor slave&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;londiste3 /etc/londiste/teste_replica_leaf.ini add-table pessoa
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;testando-a-replicação&#34;&gt;Testando a replicação&lt;/h2&gt;

&lt;p&gt;Apartir desse ponto, em alguns segundos, ambos os bancos têm os mesmos registros na tabela pessoa, veja:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@pg-slave ~]# psql -U postgres -d teste_replica -c &#39;SELECT COUNT(1) FROM pessoa;&#39; -h 192.168.152.149
 count 
-------
  1000
(1 row)

[root@pg-slave ~]# psql -U postgres -d teste_replica -c &#39;SELECT COUNT(1) FROM pessoa;&#39; -h 192.168.152.150
 count 
-------
  1000
(1 row)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Também, não é possível fazer alterações nos registros do servidor slave:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;[root@pg-slave ~]# psql -U postgres -d teste_replica -h 192.168.152.150
psql (9.3.4)
Type &amp;quot;help&amp;quot; for help.

teste_replica=# delete from pessoa;
ERROR:  Table &#39;public.pessoa&#39; to queue &#39;q_teste_replica&#39;: change not allowed (D)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Daqui pra frente, qualquer alteração será replicada (desde que a estrutura da tabela seja a mesma).&lt;/p&gt;

&lt;p&gt;Referências:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/markokr/skytools&#34;&gt;https://github.com/markokr/skytools&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dba.stackexchange.com/questions/1742/how-to-insert-file-data-into-a-postgresql-bytea-column&#34;&gt;http://dba.stackexchange.com/questions/1742/how-to-insert-file-data-into-a-postgresql-bytea-column&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Automatizando os reports do PGBadger</title>
      <link>http://swebber.me/blog/2013/11/04/automatizando-reports-pgbadger/</link>
      <pubDate>Mon, 04 Nov 2013 00:58:11 -0200</pubDate>
      
      <guid>http://swebber.me/blog/2013/11/04/automatizando-reports-pgbadger/</guid>
      <description>&lt;p&gt;Minha idéia com esse post é &amp;lsquo;despejar&amp;rsquo; uma série de scripts e configurações pra que o &lt;a href=&#34;http://dalibo.github.io/pgbadger/&#34;&gt;pgbadger&lt;/a&gt; gere quase que automaticamente os reports, seguindo a regra de tempo abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Report dos últimos 30min&lt;/li&gt;
&lt;li&gt;da última 1h&lt;/li&gt;
&lt;li&gt;das últimas 3h&lt;/li&gt;
&lt;li&gt;das últimas 6h&lt;/li&gt;
&lt;li&gt;do último dia&lt;/li&gt;
&lt;li&gt;da última semana&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Além da configuração padrão, sugerida no site do próprio pgbadger, é necessário configurar o syslog, para que ele direcione os logs do postgres para um arquivo separado, assim, adicione esse trecho no arquivo /etc/rsyslog.conf:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;local0.*        -/var/log/pgsql/pgsql.log
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Pode ser necessário criar o diretório /var/log/pgsql, se explodir qualquer erro aí, confirme se o mesmo foi criado. :D&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Após isso, dê um reload no serviço e os logs do postgres serão criados nesse diretório.&lt;/p&gt;

&lt;p&gt;É necessário configurar o LogRotate para que o mesmo rotacione os logs. Baseado nas regras acima, crie o arquivo &lt;code&gt;/etc/pgsql/cron.logrotate&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/var/log/pgsql/pgsql.log {
    missingok
    rotate 1488
    nomail
    sharedscripts
    create 0660 root root
    postrotate
    /etc/init.d/rsyslog restart
    /etc/init.d/postgresql-9.2 reload
    endscript
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Crie um script para gerar os reports, chamado update_badger.sh:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

filter_mask=&amp;quot;$1&amp;quot;
filter_mask_cmd=&#39;mmin&#39;
file_name=&amp;quot;/var/www/html&amp;quot;

if [ $filter_mask = &amp;quot;30min&amp;quot; ]; then
  filter_mask=30
  file_name=&amp;quot;${file_name}/index.html&amp;quot;
elif [ $filter_mask = &amp;quot;1h&amp;quot; ]; then
  filter_mask=60
  file_name=&amp;quot;${file_name}/last-1h.html&amp;quot;
elif [ $filter_mask = &amp;quot;3h&amp;quot; ]; then
  filter_mask=300
  file_name=&amp;quot;${file_name}/last-3h.html&amp;quot;
elif [ $filter_mask = &amp;quot;6h&amp;quot; ]; then
  filter_mask=600
  file_name=&amp;quot;${file_name}/last-6h.html&amp;quot;
elif [ $filter_mask = &amp;quot;1d&amp;quot; ]; then
  filter_mask=1
  filter_mask_cmd=&#39;mtime&#39;
  file_name=&amp;quot;${file_nam3e}/last-day.html&amp;quot;
elif [ $filter_mask = &amp;quot;1w&amp;quot; ]; then
  filter_mask=7
  filter_mask_cmd=&#39;mtime&#39;
  file_name=&amp;quot;${file_name}/last-week.html&amp;quot;
fi

echo
echo $(date) - Generating ${file_name} file...
echo
/usr/bin/pgbadger $(/bin/find /var/log/pgsql/ -${filter_mask_cmd} -$filter_mask -type f) -o ${file_name}
/bin/chown apache:apache ${file_name}
/bin/chmod 755 ${file_name}

if [ ${filter_mask} -eq 30 ]; then
  echo $(date) - Rotating log file
  /usr/sbin/logrotate -f /etc/pgsql/cron.logrotate
fi
echo $(date) - Done.
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Note que nesse script, o log rotate é chamado (com a configuração descrita anteriormente) a cada 30min. Assim, não é necessário configurar o crontab ou similar pra fazer esse trabalho sujo. ;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Agora, agende a geração dos reports no cron:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# pgbadger reports
*/30 * * * * /opt/resources/update_badger.sh 30min &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 */1 * * * /opt/resources/update_badger.sh 1h &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 */3 * * * /opt/resources/update_badger.sh 3h &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 */6 * * * /opt/resources/update_badger.sh 6h &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 00 * * * /opt/resources/update_badger.sh 1d &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 00 * * Sat /opt/resources/update_badger.sh 1w &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pra finalizar, eu fiz uma pequena modificação no pgbadger, para que ele mostre um pequeno menu dropdown com os horários dos reports disponíveis. Você pode fazer download do mesmo no github: &lt;a href=&#34;http://github.com/sebastianwebber/pgbadger&#34;&gt;https://github.com/sebastianwebber/pgbadger&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Todo caso, fica aí um screenshot da minima modificação que fiz (só pra dar um gostinho):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://swebber.me/wp-content/uploads/2013/11/badger_custom.png&#34; alt=&#34;screenshot&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Corrigindo o problema de ordenação do PostgreSQL no RHEL 6</title>
      <link>http://swebber.me/blog/2013/05/16/corrigindo-problema-ordenacao-postgresql-rhel6/</link>
      <pubDate>Thu, 16 May 2013 19:46:53 -0200</pubDate>
      
      <guid>http://swebber.me/blog/2013/05/16/corrigindo-problema-ordenacao-postgresql-rhel6/</guid>
      <description>&lt;p&gt;Sobre o ambiente:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Red Hat Enterprise Linux Server release 6.4 (Santiago)&lt;/p&gt;

&lt;p&gt;PostgreSQL 9.2.4&lt;/p&gt;

&lt;p&gt;LANG=pt_BR.UTF-8&lt;/p&gt;

&lt;p&gt;Banco de dados &lt;code&gt;teste&lt;/code&gt;, utilizando o encoding &lt;code&gt;UTF-8&lt;/code&gt; e o &lt;code&gt;LC_TYPES&lt;/code&gt; e &lt;code&gt;COLLATE&lt;/code&gt; como &lt;code&gt;pt_BR.UTF-8&lt;/code&gt;`&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Para exemplificar melhor o problema de ordenação, criei a tabela abaixo:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;teste=# create table foo (id serial primary key, nome text);
NOTICE:  CREATE TABLE will create implicit sequence &amp;quot;foo_id_seq&amp;quot; for serial column &amp;quot;foo.id&amp;quot;
NOTICE:  CREATE TABLE / PRIMARY KEY will create implicit index &amp;quot;foo_pkey&amp;quot; for table &amp;quot;foo&amp;quot;
CREATE TABLE
teste=# \d foo
                             Tabela &amp;quot;public.foo&amp;quot;
 Coluna |  Tipo   |                      Modificadores
--------+---------+----------------------------------------------------------
 id     | integer | não nulo valor padrão de nextval(&#39;foo_id_seq&#39;::regclass)
 nome   | text    |
Índices:
    &amp;quot;foo_pkey&amp;quot; PRIMARY KEY, btree (id)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;E inseri uns dados de teste:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;teste=# insert into foo (nome) values (&#39;CRIANSCA&#39;), (&#39;CRIANSCA&#39;), (&#39;CRIANÇA&#39;), (&#39;DANIEL ALDROVANO&#39;), (&#39;DANIELA LAZARUS&#39;), (&#39;DANIELA LEITE&#39;);
INSERT 0 6
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Ao listar os dados, a primeira surpresa:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;teste=# select * from foo order by nome ;
 id |              nome
----+--------------------------------
  2 | CRIANCA
  3 | CRIANÇA
  1 | CRIANSCA
  5 | DANIELA LAZARUS
  4 | DANIEL ALDROVANO
  6 | DANIELA LEITE
(6 registros)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notem que o problema em sí está na ordem dada aos IDs 5, 4 e 6. Esse problema é esperado, devido ao fato que (nesse collate especificamente) a operação de ordenação é realizada sem os espaços, assim, &lt;code&gt;DANIELALAZARUS&lt;/code&gt; vem antes de &lt;code&gt;DANIELALDROVANO&lt;/code&gt; e assim por diante.&lt;/p&gt;

&lt;p&gt;Para sanar o problema, pensei em mudar o collate para C por que o mesmo não ignora os espaços na operação de ordenação, porém surgiu um novo problema: os acentos não são ordenados corretamente.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;teste=# create collation teste (locale=&#39;C&#39;);
CREATE COLLATION
teste=# select * from foo order by nome collate teste;
 id |              nome
----+--------------------------------
  2 | CRIANCA
  1 | CRIANSCA
  3 | CRIANÇA
  4 | DANIEL ALDROVANO
  5 | DANIELA LAZARUS
  6 | DANIELA LEITE
(6 registros)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Para sanar o problema, edite o arquivo &lt;code&gt;/usr/share/i18n/locales/pt_BR&lt;/code&gt;, e adicione antes de &lt;code&gt;END LC_COLLATE&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;reorder-after &amp;lt;U00A0&amp;gt;
&amp;lt;U0020&amp;gt;&amp;lt;CAP&amp;gt;;&amp;lt;CAP&amp;gt;;&amp;lt;CAP&amp;gt;;&amp;lt;U0020&amp;gt;
reorder-end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Aplique as modificações, rodando o comando abaixo:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;localedef -i pt_BR -c -f UTF-8 -A /usr/share/locale/locale.alias pt_BR
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Após configurar o locale, reinicie o banco de dados.&lt;/p&gt;

&lt;p&gt;Assim os dados são ordenados corretamente:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;teste=# select * from foo order by nome;
 id |              nome
----+--------------------------------
  2 | CRIANCA
  3 | CRIANÇA
  1 | CRIANSCA
  4 | DANIEL ALDROVANO
  5 | DANIELA LAZARUS
  6 | DANIELA LEITE
(6 registros)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Em especial, um obrigado ao &lt;a href=&#34;http://fabriziomello.github.io/&#34;&gt;@fabriziomello&lt;/a&gt; pela dica.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Listando as 10 maiores tabelas no PostgreSQL</title>
      <link>http://swebber.me/blog/2013/01/22/listando-as-10-maiores-tabelas-no-postgresql/</link>
      <pubDate>Tue, 22 Jan 2013 19:43:26 -0200</pubDate>
      
      <guid>http://swebber.me/blog/2013/01/22/listando-as-10-maiores-tabelas-no-postgresql/</guid>
      <description>&lt;p&gt;Para listar as maiores tabelas do seu banco de dados, utilize a consulta abaixo:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/sebastianwebber/ebe4810bf03278624e31.js&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
    <item>
      <title>Primeiras impressões do xDB Replication Server</title>
      <link>http://swebber.me/blog/2013/01/08/primeiras-impressoes-do-xdb-replication-server/</link>
      <pubDate>Tue, 08 Jan 2013 19:27:58 -0200</pubDate>
      
      <guid>http://swebber.me/blog/2013/01/08/primeiras-impressoes-do-xdb-replication-server/</guid>
      <description>

&lt;p&gt;O &lt;a href=&#34;http://www.enterprisedb.com/products-services-training/products-overview/xdb-replication-server-multi-master&#34;&gt;xDB Replication Server&lt;/a&gt; é o produto da &lt;a href=&#34;http://www.enterprisedb.com&#34;&gt;EnterpriseDB&lt;/a&gt; que permite replicação assincrona tanto Single-Master (ou Master/Slave) quanto Multi-Master para banco de dados PostgreSQL/PostgreSQL Plus. O produto tem um funcionamento bem similar a replicação através de &lt;a href=&#34;http://msdn.microsoft.com/en-us/library/ms152567.aspx&#34;&gt;publicação do SQL Server&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;A finalidade desse teste foi replicar tabelas disponibilizadas no Oracle para uma base PostgreSQL.&lt;/p&gt;

&lt;p&gt;Para minha surpresa, na atual versão do produto (5.0-2), a replicação Multi-master apenas está disponível para o PostgreSQL/PostgreSQL Plus. Quanto a Single-Master, não há problemas em utilizar Oracle ou SQL Server. Todos os testes realizados foram realizados com o Oracle como master e o PostgreSQL como slave. Acredito que o contrário (PostgreSQL –&amp;gt; Oracle) possa funcionar normalmente.&lt;/p&gt;

&lt;h3 id=&#34;ambiente-de-testes&#34;&gt;Ambiente de testes&lt;/h3&gt;

&lt;h4 id=&#34;banco-master-oracle&#34;&gt;Banco Master – Oracle&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Versão:&lt;/strong&gt; Oracle 11GR2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sistema Operacional:&lt;/strong&gt; Red Hat Enterprise Linux Server release 5.6 (Tikanga)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plataforma:&lt;/strong&gt; x86_64&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;banco-slave-postgresql&#34;&gt;Banco Slave – PostgreSQL&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Versão:&lt;/strong&gt; PostgreSQL 8.4.13&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sistema Operacional:&lt;/strong&gt; CentOS release 6.3 (Final)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Plataforma:&lt;/strong&gt; x86_64&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Produto:&lt;/strong&gt; xDB Replication Server 5.0-2&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;h3 id=&#34;observações&#34;&gt;Observações&lt;/h3&gt;

&lt;p&gt;Propositalmente o Oracle está sendo executado em outro local e, necessariamente, em outra cidade. Para facilitar o ambiente, tanto o servidor Publicação quanto Subscrição estão rodando no mesmo servidor que está rodando o PostgreSQL e, especificamente, configurados no banco de dados ‘postgres’.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;na-prática&#34;&gt;Na prática&lt;/h3&gt;

&lt;p&gt;Após liberar acesso aos servidores através de VPN e criar usuários e definir permissões de acesso ao usuário ‘hr’ no Oracle, criamos a tabela ‘tabela_teste’ com as colunas descritas abaixo:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Nome&lt;/th&gt;
&lt;th&gt;Tipo&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;NUMBER(30,0)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;nome&lt;/td&gt;
&lt;td&gt;VARCHAR2(2048)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;p&gt;Ao mandar realizar um snapshot dados, ocorreu o erro abaixo:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Disabling FK constraints &amp;amp; triggers on hr.tabela_teste before truncate… Error Loading Data into Table: TABELA_TESTE: ERROR: relation “hr.tabela_teste” does not exist at position 67&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Assim notei o primeiro problema: &lt;strong&gt;é necessário ter a mesma estrutura das tabelas publicadas no servidor destino&lt;/strong&gt; (mesmo schema inclusive) para que a replicação funcione.&lt;/p&gt;

&lt;p&gt;Após criar a tabela no PostgreSQL, fizemos um novo teste: Adicionar uma coluna do tipo CLOB. Após criar a mesma coluna em nossa tabela no PostgreSQL. A replicação deixou de funcionar, com isso foi identificado incompatibilidade com os tipos de dados binários.&lt;/p&gt;

&lt;p&gt;Nosso teste final cobria o uso de campos data/hora. Assim, foi adicionado uma nova coluna na tabela e a mesma foi replicada seguindo a ordem das colunas e isso resultou o seguinte problema:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hr=# select * from hr.tabela_teste order by id;
 id | nome |                 pdf                  | data
----+------+--------------------------------------+------
  1 |      | 2012-01-08 00:00:00.000000 -02:00:00 |
  2 |      | 2012-01-08 00:00:00.000000 -02:00:00 |
  3 |      | 2012-01-08 00:00:00.000000 -02:00:00 |
  4 |      | 2012-01-08 00:00:00.000000 -02:00:00 |
  5 |      | 2012-01-08 00:00:00.000000 -02:00:00 |
  6 |      | 2013-01-08 10:44:51.000000 -02:00:00 |
  7 |      | 2013-01-08 10:44:51.000000 -02:00:00 |
  8 |      | 2013-01-08 10:54:36.000000 -02:00:00 |
  9 |      | 2013-01-08 10:54:36.000000 -02:00:00 |
 10 |      | 2013-01-08 10:54:36.000000 -02:00:00 |
(10 rows)

hr=# \d hr.tabela_teste
             Table &amp;quot;hr.tabela_teste&amp;quot;
 Column |            Type             | Modifiers
--------+-----------------------------+-----------
 id     | integer                     | not null
 nome   | text                        |
 pdf    | bytea                       |
 data   | timestamp without time zone |
Indexes:
    &amp;quot;tabela_teste_pk&amp;quot; PRIMARY KEY, btree (id)
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;O problema foi normalizado apenas quando a coluna pdf foi excluida.&lt;/p&gt;

&lt;p&gt;Por fim, foi realizada uma carga de dados nessa tabela para levantarmos o tempo de resposta (&lt;a href=&#34;http://helkmut.blogspot.com.br/2013/01/oracle-populando-tabelas-com-clob-e.html&#34;&gt;detalhes da carga aqui&lt;/a&gt;). Enquanto tentamos popular a tabela ocorreu mais uma surpresa:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;ORA-01438: valor maior que a precisão especificada usado para esta coluna
ORA-06512: em “HR.RRPI_HR_TABELA_TESTE”, line 2
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Pelo que identificamos o problema ocorre nas tabelas de controle da replicação que são criadas baseadas na estrutura da tabela original. Como antes da carga aumentamos o tamanho do campo para poder inserir mais registros as tabelas de controle não foram alteradas acabou causando esse erro.&lt;/p&gt;

&lt;h3 id=&#34;conclusões&#34;&gt;Conclusões&lt;/h3&gt;

&lt;h4 id=&#34;o-que-ele-faz&#34;&gt;O que ele faz&lt;/h4&gt;

&lt;p&gt;O xDB Replication Server permite fazer replicação de pacotes de dados entre multiplos servidores, sejam eles PostgreSQL/PostgreSQL Plus, Oracle ou SQL Server de forma assincrona. Atualmente apenas o PostgreSQL/PostgreSQL Plus tem disponível o modelo Multi-Master.&lt;/p&gt;

&lt;h4 id=&#34;o-que-ele-não-faz&#34;&gt;O que ele não faz&lt;/h4&gt;

&lt;p&gt;Com o produto não é possível criar qualquer solução de alta disponibilidade. Basicamente o produto mantém uma cópia das tabelas da base origem, na base destino.&lt;/p&gt;

&lt;h4 id=&#34;pontos-positivos&#34;&gt;Pontos positivos&lt;/h4&gt;

&lt;p&gt;Pelo fato de o mesmo replicar os dados em suas tabelas de controle, caso o servidor de subscrições esteja indisponível, os dados serão analisados quando ele se tornar disponível e assim executar todas as tarefas necessárias para manter os dados iguais em ambos os lados. É possível, também, efetuar filtros dos dados a serem copiados e assim diminir o tempo de carga de um servidor para outro. Por fim, é possível agendar para que replica dos dados seja atualizada de tempos em tempos pela própria interface do xDB Replication Console, sem depender de componentes do SO ou ferramentas de terceiros.&lt;/p&gt;

&lt;h4 id=&#34;pontos-negativos&#34;&gt;Pontos negativos&lt;/h4&gt;

&lt;p&gt;A primeira limitação que incomodou é que, pelo menos através do xDB Replication Console, não foi possível criar a estrutura de tabelas automaticamente. É possível que, em ambientes que a publicação contenha muitas tabelas, ocorram muitos problemas devido a divergencia das tabelas ou colunas entre os servidores. A replicação dos dados é feita através de triggers nas tabelas que fazem parte da publicação e as alterações ficam gravadas em tabelas de controle. Além do fato gravação dos dados nessas tabelas concorrer com as outras transações, em nossos testes, essas tabelas de controle não eram alteradas quando realizadas mudanças nas tabelas alvo e assim impedindo a replicação de funcionar. Na interface de administração, não encontrei opção para atualizar-las e a única solução que encontrei foi recriar a publicação. Há algumas restrições quanto aos tipos de dados, em especial os binários. Não há opção para selecionar quais colunas serão replicadas (nem como uma consulta ao invés de um objeto) e também não conseguimos mapear views, sejam materializadas ou não.&lt;/p&gt;

&lt;p&gt;Em especial, obrigado ao &lt;a href=&#34;http://helkmut.blogspot.com.br&#34;&gt;Gabriel&lt;/a&gt;, pela ajuda com a integração com o Oracle.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Listando os próximos jobs do pgagent</title>
      <link>http://swebber.me/blog/2012/12/10/listando-os-proximos-jobs-do-pgagent/</link>
      <pubDate>Mon, 10 Dec 2012 19:25:49 -0200</pubDate>
      
      <guid>http://swebber.me/blog/2012/12/10/listando-os-proximos-jobs-do-pgagent/</guid>
      <description>&lt;p&gt;Para listar os próximos jobs, execute a consulta abaixo no banco postgres (ou o banco que tem o pgagent instalado):&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/sebastianwebber/763e5fc88549d1d2a3708a1e2b0eb216.js&#34;&gt;&lt;/script&gt;
</description>
    </item>
    
  </channel>
</rss>