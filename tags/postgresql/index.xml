<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Postgresql on SWebber IT Services</title>
    <link>http://swebber.me/tags/postgresql/index.xml</link>
    <description>Recent content in Postgresql on SWebber IT Services</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>sebastian@swebber.me (Sebastian Webber)</managingEditor>
    <webMaster>sebastian@swebber.me (Sebastian Webber)</webMaster>
    <copyright>This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.</copyright>
    <atom:link href="http://swebber.me/tags/postgresql/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>O Autovacuum do PostgreSQL não é o inimigo!</title>
      <link>http://swebber.me/blog/2016/11/14/autovacuum-nao-e-o-inimigo/</link>
      <pubDate>Mon, 14 Nov 2016 14:10:41 -0200</pubDate>
      <author>sebastian@swebber.me (Sebastian Webber)</author>
      <guid>http://swebber.me/blog/2016/11/14/autovacuum-nao-e-o-inimigo/</guid>
      <description>

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;ATENÇÃO!&lt;/strong&gt; Este post é uma tradução para Português do Brasil do &lt;a href=&#34;https://www.citusdata.com&#34;&gt;blog da citusdata&lt;/a&gt;, escrito pelo Sr. Joe Nelson. O post original pode ser encontrado na URL abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/&#34;&gt;https://www.citusdata.com/blog/2016/11/04/autovacuum-not-the-enemy/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fique a vontade para comentar quaisquer problemas na tradução.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;É um equívoco comum que workloads com grandes volumes de leituras e escritas no PostgreSQL inevitavelmente causam ineficiencia no banco de dados. Nós ouvimos casos aonde os usuários encontram lentidões fazendo apenas algumas centenas de gravações por segundo e recorrem a sistemas como Dynamo ou Cassandra por frustração. No entanto, o PostgreSQL pode lidar com essas cargas de trabalho sem nenhum problema, desde que ele esteja configurado corretamente.&lt;/p&gt;

&lt;p&gt;O problema deriva do que é conhecido como &amp;ldquo;inchaço&amp;rdquo;, um fenômeno do PostgreSQL e de outros bancos de dados MVCC que causa o aumento do espaço em disco e uma baixa no desempenho. Vamos ver como o &lt;code&gt;Autovacuum&lt;/code&gt;, uma ferramenta que combate o inchaço, é tipicamente incompreendida e mal configurada. Ao falar num baixo nível sobre os componentes internos do PostgreSQL vamos chegar numa melhor configuração para o &lt;code&gt;Autovacuum&lt;/code&gt;. Finalmente vamos considerar como distribuir os dados sob um cluster PostgreSQL como o Citus também pode combater o inchaço.&lt;/p&gt;

&lt;h2 id=&#34;problemas-no-paraíso-do-mvcc&#34;&gt;Problemas no paraíso do MVCC&lt;/h2&gt;

&lt;p&gt;Aqui o problema começa: Arquitetos de bancos de dados desejam permitir transações read-only num banco de dados para retornar os dados sem bloquear as atualizações concorrentes. Fazendo isso, se reduz a latência das requisições em ambientes com leitura pesada, comum em aplicações web.&lt;/p&gt;

&lt;p&gt;Entretanto, para permitir que leituras contínuas prossigam sem pausa, é necessário manter um snapshot diferente do mundo para algumas requisições e finalmente conciliar as diferenças. Essas &amp;ldquo;pequenas mentiras&amp;rdquo; ficam sujeitas a uma penalidade de espaço, familiar a todas as mentiras - você vai precisar de uma boa memória para manter o histórico em ordem.&lt;/p&gt;

&lt;p&gt;O PostgreSQL e outros bancos de dados relacionais usam uma técnica chamada Multi-Version Concurrency Control (MVCC) para manter o controle de cada transação e a penalidade de espaço do MVCC é chamada de inchaço. O PostgreSQL é uma máquina de inchaço e ele vai inchar sem escrúpulos. O PostgreSQL precisa de ajuda de uma ferramenta externa chamada &lt;code&gt;VACUUM&lt;/code&gt; para ter uma chance de limpar essa &amp;ldquo;sujeira&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;Por razões que vamos ver mais tarde, tabelas e índices inchados não somente disperdiçam espaço mas também deixam as consultas mais lentas. Então isso não é só uma questão de conseguir um disco rigido maior e esquecer sobre o inchaço. Onde há atualizações nos dados há inchaço e é com você executar o &lt;code&gt;VACUUM&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Não é tão ruim quanto costumava ser. Num passado distante (antes do PostgreSQL 8), os DBAs tinham que executar o &lt;code&gt;VACUUM&lt;/code&gt; manualmente. Eles tinham que balancear o consumo de recursos contra a carga (load average) do banco de dados existente para decidir quando executa-lo e potencialmente quando interrompe-lo. Hoje em dia podemos configurar o daemon do &lt;code&gt;Autovacuum&lt;/code&gt; para executar essas limpezas nos momentos mais oportunos.&lt;/p&gt;

&lt;p&gt;O &lt;code&gt;Autovacuum&lt;/code&gt; funciona bem quando configurado corretamente. Entretando, suas configurações padrão são apropriadas para bancos de dados com algumas centenas de mega bytes de tamanho e não é agressivo o bastante para grandes bancos de dados. Em ambientes de produção ele começa a ficar pra trás.&lt;/p&gt;

&lt;p&gt;Quando o &lt;code&gt;VACUUM&lt;/code&gt; ficar pra trás ele vai consumir mais recursos quando ele é executado e isso vai interferir na operação normal das consultas. Isso pode levar à um circulo vicioso aonde os administradores de bancos de dados reconfiguram erroniamente o &amp;ldquo; devorador de recursos &lt;code&gt;Autovacuum&lt;/code&gt;&amp;rdquo; pra rodar com menos frequência ou não rodar mais. O &lt;code&gt;Autovacuum&lt;/code&gt; não é o ínimigo e &lt;strong&gt;desabilitá-lo é desastroso&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;a-magreza-no-inchaço&#34;&gt;A magreza no inchaço&lt;/h2&gt;

&lt;p&gt;O PostgreSQL numera cada nova transação com um identificador incremental (&lt;code&gt;txid&lt;/code&gt;). Todas as linhas na tabela também possuem colunas escondidas (&lt;code&gt;xmin&lt;/code&gt;, &lt;code&gt;xmax&lt;/code&gt;) gravando o &lt;code&gt;transaction id&lt;/code&gt; mínimo e máximo que são permitidos ver o registro. Você pode imaginar o comando &lt;code&gt;SELECT&lt;/code&gt; incluindo implicitamente &lt;code&gt;WHERE xmin &amp;lt;= txid_current() AND (xmax = 0 OR txid_current() &amp;lt; xmax)&lt;/code&gt;. Registros que não possuem nenhuma transação ativa ou no futuro podem ser consideradas &amp;ldquo;mortos&amp;rdquo;. Isso significa que não há transações ativas com &lt;code&gt;xmin ≤ txid &amp;lt; xmax&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Novos registros ou registros atualizados utilizam o &lt;code&gt;txid&lt;/code&gt; da transação que o criou para o seu &lt;code&gt;xmin&lt;/code&gt; e registros apagados definem o &lt;code&gt;xmax&lt;/code&gt; com o &lt;code&gt;txid&lt;/code&gt; que o deletou.&lt;/p&gt;

&lt;p&gt;Ilustração rápida:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;begin;

select txid_current(); -- supostamente vai retornar 1
create table foo (bar integer);
insert into foo (bar) values (100);

select xmin, xmax from foo;

commit;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Vai retornar:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;┌──────┬──────┐
│ xmin │ xmax │
├──────┼──────┤
│    1 │    0 │
└──────┴──────┘
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Se atualizarmos o registro, o &lt;code&gt;xmin&lt;/code&gt; vai avançar:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;begin;

update foo set bar = 200;
select xmin, xmax from foo;

commit;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Isso retorna:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;┌──────┬──────┐
│ xmin │ xmax │
├──────┼──────┤
│    2 │    0 │
└──────┴──────┘
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O que não é exibido é que agora há um registro morto na tabela. Atualizando o registro efetivamente apaga-o e insere-0 com os valores alterados. O registro que estamos vendo foi recentemente inserido (pelo  &lt;code&gt;txid&lt;/code&gt; 2) e o registro original está no disco com &lt;code&gt;xmix=1, xmax=2&lt;/code&gt;. Podemos confirmar perguntando por informações sobre as tuplas (registros) nessa tabela.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create extension pgstattuple;

select tuple_count, dead_tuple_count from pgstattuple(&#39;public.foo&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;┌─────────────┬──────────────────┐
│ tuple_count │ dead_tuple_count │
├─────────────┼──────────────────┤
│           1 │                1 │
└─────────────┴──────────────────┘
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;O PostgreSQL também provê uma API de baixo nível para ver informações sobre o armazenmaneto físico das páginas de bancos de dados (pedaços da tabela armazenados no disco). Essa API nos permite ver o &lt;code&gt;xmin&lt;/code&gt; e &lt;code&gt;xmax&lt;/code&gt; de todas as linhas e, apesar de algumas considerações de segurança, os valores dos registros apagados não sÃo visíveis.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;create extension pageinspect;

select t_xmin, t_xmax from heap_page_items(get_raw_page(&#39;foo&#39;, 0));
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;┌────────┬────────┐
│ t_xmin │ t_xmax │
├────────┼────────┤
│      1 │      2 │
│      2 │      0 │
└────────┴────────┘
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Nesse ponto você pode ver um jeito de gerar o inchaço: é só continuamente atualizar muitos registros de uma tabela. Se o &lt;code&gt;Autovacuum&lt;/code&gt; foi desabilitado, o tamanho da tabela vai continuar a aumentar mesmo que o número de registros visiveis continue o mesmo. Um outro jeito de causar o inchaço é inserir uma grande quantidade de registros dentro de uma transação mas executar o &lt;code&gt;ROLLBACK&lt;/code&gt; ao invés do &lt;code&gt;COMMIT&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Se o &lt;code&gt;Autovacuum&lt;/code&gt; está rodando, ele pode limpar esses registros mortos &lt;em&gt;a menos que&amp;hellip;&lt;/em&gt; os registros apagados são impedidos de morrer! Nesse cenário de filmes de terror uma transação está rodando por muito tempo (como uma consulta analítica) e seus &lt;code&gt;txid&lt;/code&gt; previnem registros como de serem marcados como mortos, mesmo quando apagados por outro comando. A consulta que está rodando a muito tempo nem precisa consultar os registros apagados, a presença dos registros quando a consulta iniciou garante que elas não podem ser removidas. Combinar OLTP e consultas analíticas que rodam por muito tempo é um cocktail perigoso.&lt;/p&gt;

&lt;p&gt;Fora o intratável apocalipse zumbi acíma, o &lt;code&gt;Autovacuum&lt;/code&gt; pode deixar as coisas sob controler com a configuração adequada. Vamos ver algumas consenquências do inchaço antes de considerar o &lt;code&gt;Autovacuum&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;o-inchaço-e-a-velocidade-das-consultas&#34;&gt;O inchaço e a velocidade das consultas&lt;/h2&gt;

&lt;p&gt;Além de simplismente ser um disperdício de espaço, o inchaço prejudica a velocidade da consulta. Cada tabela e seu índice é armazenado num array de páginas de tamanho fixo (normalmente de &lt;code&gt;8KB&lt;/code&gt;). Quando a consulta solicita os registros, o banco de dados carrega essas páginas na memória. Quanto mais registros mortos por página, mais &lt;code&gt;I/O&lt;/code&gt; é disperdiçado na carga dos dados para a memória. Por exemplo: &lt;strong&gt;uma leitura sequencial precisa carregar e passar por todos registros mortos&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;O inchaço também torna menos provavel que os registros ativos para consulta vão caber na memória todos de uma vez. Inchaços fazem registros vivos mais dispersos por página física e, consenquêntemente, mais páginas são necessárias em memória para o mesmo número de registros &amp;ldquo;vivos&amp;rdquo;. Isso causa swap e torna alguns algoritmos e planos de consulta inaceitaveis para execução.&lt;/p&gt;

&lt;p&gt;Um caso de inchaço desagradavel é o &lt;a href=&#34;https://www.postgresql.org/docs/current/static/catalogs.html&#34;&gt;próprio catálogo&lt;/a&gt; do PostgreSQL. &lt;strong&gt;O catalogo pode inchar por que eles também são tabelas.&lt;/strong&gt; Um jeito de causar isso acontecer é através das tabelas temporárias, constantemente criando e apagando. Isso causa constantes atualizações nas tabelas do catálogo. Quando o catálogo está inchado, as funções administrativas ficam lentas e até coisas como rodar um &lt;code&gt;\d&lt;/code&gt; no psql é lento.&lt;/p&gt;

&lt;p&gt;Índices ficam inchados também. Um índice é um mapeamento de chaves de valores de dados para identificadores de registros. Esses identificadores nomeiam a página do &lt;code&gt;heap&lt;/code&gt; (também conhecimento como o arquivo que a tabela é armazeada) e  o intervalo dentro da página. Cada registro é um objeto independente que precisa sua própria entrada no índice. &lt;strong&gt;Uma atualização no registro sempre cria uma nova entrada no índice para o registro&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;A degradação do desempenho dos índices é menos grave do que das tabelas por algumas razões. Uma entrada do índice que aponta para um registro morto pode ser marcado como morto. Isso deixa o índice inchado em tamanho mas não leva a fazer pesquisas desnecessárias no &lt;code&gt;heap&lt;/code&gt;. Atualizações nos registros do &lt;code&gt;heap&lt;/code&gt; que não afetam a(s) coluna(s) do índice usam uma técnica chamada HOT para fornecer ponteiros para os registros mortos para sua substituição. Isso permite consultas tu reutilizar antigas entradas no índice através do heap.&lt;/p&gt;

&lt;p&gt;As considerações do tamanho do inchaço do índice ainda são significativas. Por exemplo, um índice &lt;code&gt;btree&lt;/code&gt; consiste numa arvore binária de páginas (do mesmo tamanho de páginas que você encontra no &lt;code&gt;heap&lt;/code&gt;). A página folha contém valores e identificadores de registros. Atualizações aleatórias na tabela tendem a deixar o índice &lt;code&gt;btree&lt;/code&gt; em forma por que ele pode reutilizar as páginas. Entretanto, inserções ou atualizações assimétricas que afetam um lado da arvore,&lt;/p&gt;

&lt;p&gt;Para verificar se um índice btree é eficiente usando suas páginas você pode perguntar a função &lt;code&gt;pgstatindex&lt;/code&gt;. A média de densidade da folha é a porcentagem do uso da página de índice de folha:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;SELECT avg_leaf_density FROM pgstatindex(&#39;btree_index_name&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ajustando-o-autovacuum&#34;&gt;Ajustando o Autovacuum&lt;/h2&gt;

&lt;p&gt;O Autovacuum deixa o banco de dados rápido e em bom estado. Ele começa a trabalhar quando certas condições configuráveis são atingidas e faz uma pausa quando ele detecta que está sendo muito intrusivo para as consultas.&lt;/p&gt;

&lt;p&gt;Para todo banco de dados no cluster, o Autovacuum tenta iniciar um worker a cada &lt;code&gt;autovacuum_naptime&lt;/code&gt; (a cada minuto por padrão). Ele vai rodar no máximo &lt;code&gt;autovacuum_max_workers&lt;/code&gt; (3 por padrão) a cada vez.&lt;/p&gt;

&lt;p&gt;Cada worker procura por uma tabela que precisa de ajuda. O worker procura por tabelas aonde as estatíticas do PostgreSQL indicam um número grande o bastante de registros alterados ao tamanho da tabela. Cada worker em particular procura por uma tabela que filtra &lt;code&gt;[ESTIMATIVA DE REGISTROS INVALIDADOS] ≥ autovacuum_vacuum_scale_factor * [TAMANHO ESTIMADO DA TABELA] + autovacuum_vacuum_threshold&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;O worker começa removendo os registros mortos da tabela e compactando as páginas. Conforme cada worker avança, ele faz uma contagem de &amp;ldquo;I/O credits&amp;rdquo; que eles estão consumindo. Diferentes tipos de ações contam para créditos variáveis (os valores são configuráveis). Quando os créditos usados excedem o &lt;code&gt;autovacuum_vacuum_cost_limit&lt;/code&gt;, o Autovacuum pausa todos os workers em &lt;code&gt;autovacuum_vacuum_cost_delay&lt;/code&gt; milissegundos.&lt;/p&gt;

&lt;p&gt;Executar o vacuum é uma corrida contra o tempo. Quando compacta as páginas, o vacuum worker escaneia o &lt;code&gt;heap&lt;/code&gt; procurando por registros mortos e adiciona-os numa lista. Ele usa essa lista para primeiro apagar as entradas de ponteiro no índice para essas linhas e então, remove a linha do &lt;code&gt;heap&lt;/code&gt;. Se há muitos registros para limpar e &lt;code&gt;maintenance_work_mem&lt;/code&gt; é limitada, o worker não vai conseguir processar muitos registros mortos a cada execução e vai perder tempo repetindo esse processo com mais frequência.&lt;/p&gt;

&lt;p&gt;Isso explica uma maneira que o Autovacuum fica pra trás: quando há muitos registros mortos acumulados e o Autovacuum não possui &lt;code&gt;maintenance_work_mem&lt;/code&gt; o suficiente para removê-los rapidamente e além disso fica limitado ao &lt;code&gt;vacuum_cost_limit&lt;/code&gt;. Isso fica nítido em grandes tabelas no banco de dados. Os valores padrão no banco de dados para &lt;code&gt;autovacuum_vacuum_scale_factor = 0.2&lt;/code&gt; podem ser apropriados para pequenas tabelas, mas é muito grande para tabelas maiores. Você pode configurar o parâmetro por tabela:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;ALTER TABLE &amp;lt;tablename&amp;gt;
  SET autovacuum_vacuum_scale_factor = 0.01;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Isso quer dizer que, para tabelas com milhões de registros, o Autovacuum deve iniciar depois de 10 mil registros serem invalidados ao invés de dozentos mil. Isso ajuda a deixar o inchaço sob controle.&lt;/p&gt;

&lt;p&gt;Autovacuum também pode ficar pra trás quando há mais tabelas inchadas do que que &lt;code&gt;autovacuum_max_workers&lt;/code&gt; e todas as tabelas continuam a inchar. Workers não conseguem chegar em todas as tabelas.&lt;/p&gt;

&lt;p&gt;Aqui há ajustes sensíveis ao Autovacuum. Eles não vão funcionar para todos os bancos de dados, é claro, mas vão te levar pra direção correta.&lt;/p&gt;

&lt;table class=&#34;table&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Variável&lt;/th&gt;
            &lt;th&gt;PG Default&lt;/th&gt;
            &lt;th&gt;Sugestão&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_max_workers&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;3&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;5&lt;/code&gt; ou &lt;code&gt;6&lt;/code&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;maintenance_work_mem&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;64MB&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;system ram * 3/(8*autovacuum max workers)&lt;/code&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_vacuum_scale_factor&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;0.2&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Para grandes tabelas, tente &lt;code&gt;0.01&lt;/code&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_vacuum_threshold&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;50&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Pode ser grande para tabelas pequenas&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_vacuum_cost_limit&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;200&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Provavelmente deixe assim&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;code&gt;autovacuum_vacuum_cost_delay&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;&lt;code&gt;20ms&lt;/code&gt;&lt;/td&gt;
            &lt;td&gt;Você pode baixar caso esteja OK com mais cara de I/O durante o vacuum&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;fique-de-olho&#34;&gt;Fique de olho&lt;/h2&gt;

&lt;p&gt;Após ajustar as configurações do Autovacuum, você deve esperar e observar como o banco de dados responde. De fato, você pode querer observar o banco de dados durante um tempo &lt;em&gt;antes&lt;/em&gt; de ajustar as configurações pra evitar qualquer otimização prematura. Você deve procurar pela taxa de variação ou pela porcentagem de inchaço nas tabelas e índices.&lt;/p&gt;

&lt;p&gt;Utilize esses scripts pra coletar métricas: &lt;a href=&#34;https://github.com/pgexperts/pgx_scripts/tree/master/bloat&#34;&gt;pgexperts/pgx_scripts&lt;/a&gt;. Execute-os na cron job para acompanhar seu progresso semana à semana.&lt;/p&gt;

&lt;h2 id=&#34;divida-o-trabalho&#34;&gt;Divida o trabalho&lt;/h2&gt;

&lt;p&gt;Tabelas imensas tem um grande potencial para inchaço, tanto da baixa sensibilidade do fator de escala do VACUUM e geralmente devido a extensas rotatividades de registros. Divindido horizontalmente grandes tabelas em pequenas tabelas pode ser útil, especialmente se há um grande numero de workers do Autovacuum uma vez que cada workers pode executar uma tabela por vez. Mesmo assim, executar mais workers exigem maiores usos do &lt;code&gt;maintenance_work_mem&lt;/code&gt;. Uma solução  que, divide grandes tabelas e aumenta a capacidade de executar workers do Autovacuum é utilizar um banco de dados distrubuido composto por multiplos servidores PostgreSQL físicos  e tabelas fragmentadas.&lt;/p&gt;

&lt;p&gt;Não são apenas consultas de usuário que podem escalar num banco de dados distribuido, o VACUUM também. Pra ser justo, se as consultas estão escalando normalmente numa simples instância PostgreSQL e o único problema é o inchaço, mudar para um sistema distribuído é um exagero; Há outras maneiras de corrigir agressivamente o inchaço agúdo. No entanto, ter mais poder pra executar o VACUUM é um efeito colateral agradável em distribuir o banco de dados. É ainda mais fácil do que nunca distribuir um banco de dados PostgreSQL utilizando ferramentas de código aberto como a &lt;a href=&#34;https://github.com/citusdata/citus&#34;&gt;Citus Community Edition&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Outra alternativa é dar um passo a frente e esquecer das configurações do Autovacuum e utilizar um cluster PostgreSQL gerenciado como o &lt;a href=&#34;https://www.citusdata.com/product/cloud&#34;&gt;Citus Cloud&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Checklist mensal do PostgreSQL</title>
      <link>http://swebber.me/blog/2016/02/15/checklist-mensal-do-postgresql/</link>
      <pubDate>Mon, 15 Feb 2016 16:54:52 -0200</pubDate>
      <author>sebastian@swebber.me (Sebastian Webber)</author>
      <guid>http://swebber.me/blog/2016/02/15/checklist-mensal-do-postgresql/</guid>
      <description>

&lt;p&gt;Este post é uma humilde adaptação de um &lt;a href=&#34;http://www.jasonstrate.com/monthly-sql-server-checklist/&#34;&gt;ótimo artigo sobre o SQL Server&lt;/a&gt;. Sim, você leu certo: Peguei umas idéias do checklist do SQL Server.&lt;/p&gt;

&lt;h2 id=&#34;1-atualize-o-so-do-seu-servidor&#34;&gt;1. Atualize o SO do seu servidor&lt;/h2&gt;

&lt;p&gt;Eu sei. Você não faz isso. Acha que não precisa, que o problema não é seu, mas nos últimos anos tivemos tantos problemas de segurança recentes (&lt;a href=&#34;http://heartbleed.com&#34;&gt;HeartBleead&lt;/a&gt;, &lt;a href=&#34;https://access.redhat.com/articles/1200223&#34;&gt;Shellshock&lt;/a&gt;, etc), que sabe-se lá o que pode nos assustar no futuro. Quer uma sugestão? Atualiza tudo, sempre [que possível].&lt;/p&gt;

&lt;h2 id=&#34;2-atualize-seu-servidor-postgresql&#34;&gt;2. Atualize seu servidor PostgreSQL&lt;/h2&gt;

&lt;p&gt;Por que? por que sim, oras. Precisa de mais motivos? Então pensa que BUGs e falhas de segurança são corrigidos o quanto antes.&lt;/p&gt;

&lt;p&gt;Sua versão instalada não tem mais atualizações ou não é mais suportada? Para tudo e bora atualizar. Não só pela segurança, mas toda versão tem muita coisa bacana, aposto que os desenvolvedores implorariam pra você atualizar. Vai lá e mostra o release notes pros caras, depois vem e me agradece. :P&lt;/p&gt;

&lt;p&gt;Não acredita? Abre aí então:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://wiki.postgresql.org/wiki/What&#39;s_new_in_PostgreSQL_9.5&#34;&gt;&lt;code&gt;https://wiki.postgresql.org/wiki/What&#39;s_new_in_PostgreSQL_9.5&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Pra te dar uma dica de como atualizar, sempre dê uma lida no release notes. Lá tem tudo o que nós, meros mortais (&lt;em&gt;ou não devs&lt;/em&gt;), precisavamos saber pra atualizar o banco. Normalmente é bem simples (para o banco, atualiza os binários, sobe o banco), e caso seja mais elaborado, vai estar la no release notes, bem bonitinho.&lt;/p&gt;

&lt;p&gt;Quer saber das versões novas e tem preguiça de ver o site toda hora? Então assine o &lt;a href=&#34;http://www.postgresql.org/versions.rss&#34;&gt;feed RSS&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Ainda assim da muito trabalho? Então utilize os repositórios do PGDG, que tem pra varios sabores (&lt;a href=&#34;https://wiki.postgresql.org/wiki/Apt&#34;&gt;APT&lt;/a&gt; e &lt;a href=&#34;https://wiki.postgresql.org/wiki/RPM_Installation&#34;&gt;YUM&lt;/a&gt;  por exemplo).&lt;/p&gt;

&lt;h2 id=&#34;3-valide-suas-rotinas-de-backup&#34;&gt;3. Valide suas rotinas de backup&lt;/h2&gt;

&lt;p&gt;Verifique todo seu processo de backup. Messa os tempos de execução, documente cada etapa do processo e tente deixar ele o mais simples possível. Pontos importantes a validar são: &lt;em&gt;Tamanho ocupado&lt;/em&gt;, &lt;em&gt;duração&lt;/em&gt;, &lt;em&gt;falhas na execução&lt;/em&gt; e &lt;em&gt;monitoramento do mesmo&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Já que estamos falando de backup, faça a lição de casa e avalie as soluções de backup mais populares:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.postgresql.org/docs/current/static/backup.html&#34;&gt;DOC Oficial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pgbarman.org&#34;&gt;pgbarman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/michaelpq/pg_arman&#34;&gt;pg_arman&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.depesz.com/2013/09/11/how-to-make-backups-of-postgresql/&#34;&gt;scripts customizados do @depesz&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Já que você faz backup do seu banco, não esqueça de fazer backup das suas configurações. Afinal, nunca se sabe quando vamos precisar fazer um &lt;code&gt;Disaster Recovery&lt;/code&gt;. Falando nisso, é uma boa planejar uma solução de &lt;code&gt;HA&lt;/code&gt;, não é mesmo?&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Se você ainda usa o &lt;code&gt;pg_dump&lt;/code&gt; como sua principal solução de backup, dá uma olhada nesse &lt;a href=&#34;http://savepoint.blog.br/dump-nao-e-backup/&#34;&gt;artigo bacana do @telles&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;4-teste-com-vontade-a-sua-rotina-de-restore&#34;&gt;4. Teste, &lt;em&gt;com vontade&lt;/em&gt;, a sua rotina de restore&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Backup bom é o que restaura.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Eu nunca canso de dizer isso!&lt;/p&gt;

&lt;p&gt;Já que seu backup está rodando certinho, faça um restore dos dados. Meça os tempos, documente o processo. Se tiver como fazer isso num servidor novo, melhor aínda! O importante é ficar tranquilo e ter tudo sob controle quando a casa cair e ele for realmente necessário.&lt;/p&gt;

&lt;h2 id=&#34;5-verifique-o-desempenho-e-a-saude-do-seu-banco&#34;&gt;5. Verifique o desempenho e a saude do seu banco&lt;/h2&gt;

&lt;p&gt;Deixe de sofrer. Há muitas soluções de monitoramento no mercado (&lt;a href=&#34;http://www.zabbix.com&#34;&gt;zabbix&lt;/a&gt;, &lt;a href=&#34;https://www.nagios.org/&#34;&gt;Nagios&lt;/a&gt;, etc). Coloque ele pra funcionar e monitorar detalhes uteis do SO e também do servidor PostgreSQL. Ajuste seu log para um formato de leitura mais eficiente (como o CSV, por exemplo) e gere reports do &lt;a href=&#34;http://dalibo.github.io/pgbadger/&#34;&gt;pgbadger&lt;/a&gt; ou &lt;a href=&#34;https://prezi.com/f2dvt6m9tbf9/integrating-postgresql-with-logstash-for-real-time-monitoring/&#34;&gt;uma solução mais elaborada&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Caso você use a versão 9.3 ou superior, você &lt;strong&gt;DEVE&lt;/strong&gt; dar uma olhada no &lt;a href=&#34;http://dalibo.github.io/powa/&#34;&gt;PoWA&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;6-revise-seu-tuning-no-so-e-no-postgresql-conf&#34;&gt;6. Revise seu tuning no SO e no &lt;code&gt;postgresql.conf&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Agora que você passou a monitorar o banco, aproveita o embalo e começa a dar uma revisada no tuning do sistema operacional, começando pelo &lt;code&gt;/etc/sysctl.conf&lt;/code&gt;. Infelizmente, cada evento pode apontar um arquivo de configuração diferente. O jeito fácil é entender o que está rolando no servidor e ver se isso tu trata num dos &lt;strong&gt;3 pilares&lt;/strong&gt;: &lt;em&gt;Hardware&lt;/em&gt;, &lt;em&gt;Sistema Operacional&lt;/em&gt; e &lt;em&gt;Banco de dados&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;SO revisado? Então manda ver e da uma olhada configurações do &lt;code&gt;postgresql.conf&lt;/code&gt;. Se você nunca fez isso, eu sugiro que dê uma olhada no &lt;a href=&#34;http://pgconfig.org&#34;&gt;PGConfig&lt;/a&gt;. Lá é um bom lugar pra começar.&lt;/p&gt;

&lt;p&gt;Não esqueça do hardware. As vezes não tem jeito, precisamos de um upgrade. :D&lt;/p&gt;

&lt;h2 id=&#34;7-analise-e-ajuste-o-baseline&#34;&gt;7. Analise e ajuste o baseline&lt;/h2&gt;

&lt;p&gt;Chegou a conclusão que precisa de algum ajuste no tuning? O que mudou? Aumentou a quantidade de usuários? Nova feature baseado em &lt;a href=&#34;http://desciclopedia.org/wiki/Gambi_Design_Patterns&#34;&gt;boas praticas do mercado&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;Será que é realmente necessário esse ajuste?&lt;/p&gt;

&lt;h2 id=&#34;8-valide-o-seu-capacity-plan-https-en-wikipedia-org-wiki-capacity-planning&#34;&gt;8. Valide o seu &lt;a href=&#34;https://en.wikipedia.org/wiki/Capacity_planning&#34;&gt;Capacity Plan&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Se você tem um em ação, será que o mesmo está adequado? Se você fez algum ajuste sugerido acima, será que o mesmo não precisa de nenhum ajuste? Talvez seja o momento de mudar algumas projeções.&lt;/p&gt;

&lt;h2 id=&#34;9-sumarize-e-monte-um-plano&#34;&gt;9. Sumarize e monte um plano&lt;/h2&gt;

&lt;p&gt;Avaliou tudo o que precisa mudar? Agora monte o seu proprio plano de ação, alinhe com a equipe e batalhe pelas janelas de manutenção.&lt;/p&gt;

&lt;p&gt;Depois de tudo pronto e configurado, mande o seu próprio release notes pro pessoal do marketing e deixe eles fazerem propaganda da saude do seu banco! :P&lt;/p&gt;

&lt;h2 id=&#34;faltou-algo&#34;&gt;Faltou algo?&lt;/h2&gt;

&lt;p&gt;Certamente algo importante pode ter ficado pra trás. Deixa um comentário pra gente ajustar assim que der. :D&lt;/p&gt;

&lt;p&gt;[]&amp;rsquo;s&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Desafio sobre a replicação do PostgreSQL!</title>
      <link>http://swebber.me/blog/2016/01/21/desafio-sobre-a-replicao-do-postgresql/</link>
      <pubDate>Thu, 21 Jan 2016 20:05:03 -0200</pubDate>
      <author>sebastian@swebber.me (Sebastian Webber)</author>
      <guid>http://swebber.me/blog/2016/01/21/desafio-sobre-a-replicao-do-postgresql/</guid>
      <description>

&lt;p&gt;Esse ano, &lt;a href=&#34;http://savepoint.blog.br/10-anos-de-pgbr/&#34;&gt;segundo fontes confiáveis&lt;/a&gt;, é aniversário da Comunidade Brasileira de PostgreSQL. E pra fazer a minha parte (e tirar a poeira do blog) eu lanço um desafio público: falar sobre a replicação do PostgreSQL. E isso não é pouca coisa!&lt;/p&gt;

&lt;p&gt;Até o momento, essas são as soluções mais populares:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Replicação Nativa: &lt;a href=&#34;http://www.postgresql.org/docs/current/static/warm-standby.html#STREAMING-REPLICATION&#34;&gt;Streaming Replication&lt;/a&gt; e &lt;a href=&#34;http://www.postgresql.org/docs/current/static/warm-standby.html#STREAMING-REPLICATION-SLOTS&#34;&gt;Replication Slots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://2ndquadrant.com/en-us/resources/bdr/&#34;&gt;BDR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://2ndquadrant.com/en/resources/pglogical/&#34;&gt;PGLogical&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://slony.info/&#34;&gt;Slony&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://wiki.postgresql.org/wiki/SkyTools#Londiste&#34;&gt;Londiste&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bucardo.org/wiki/Bucardo&#34;&gt;Bucardo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.keithf4.com/mimeo-introduction/&#34;&gt;Mimeo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.pgpool.net/mediawiki/index.php/Main_Page&#34;&gt;PGpool II&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.repmgr.org/&#34;&gt;REPMgr&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;a-proposta&#34;&gt;A proposta&lt;/h2&gt;

&lt;p&gt;A idéia é fazer um ambiente de testes utilizando a versão mais recente do banco e da solução cobrindo os pontos abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Instalação e configuração&lt;/li&gt;
&lt;li&gt;Operação basica para replicar dados ou conjunto de dados&lt;/li&gt;
&lt;li&gt;Procedimentos que previnem tolerancia a falhas&lt;/li&gt;
&lt;li&gt;Validar meios para replicar dados distribuidos geograficamente&lt;/li&gt;
&lt;li&gt;Medição dos tempos de carga intensa (como o restore do banco) e moderado (como a atualização de dados e tudo mais)&lt;/li&gt;
&lt;li&gt;Avaliação de pontos fortes e fracos&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;sobre-o-ambiente-de-testes&#34;&gt;Sobre o ambiente de testes&lt;/h2&gt;

&lt;h3 id=&#34;quanto-a-máquina-virtual-dos-testes&#34;&gt;Quanto a máquina virtual dos testes&lt;/h3&gt;

&lt;p&gt;Pra simplificar o processo de setup do lab, eu criei uma configuração do &lt;a href=&#34;https://www.vagrantup.com/&#34;&gt;Vagrant&lt;/a&gt; composta de duas máquinas virtuais na configuração abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2GB de RAM&lt;/li&gt;
&lt;li&gt;35GB espaço em disco&lt;/li&gt;
&lt;li&gt;CEntOS 7 64 Bits&lt;/li&gt;
&lt;li&gt;Repositórios configurados: epel, pgdg94 e pgdg95&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Detalhes da configuração de rede:&lt;/p&gt;

&lt;table class=&#34;table&#34;&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;Hostname&lt;/th&gt;
            &lt;th&gt;IP&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;master&lt;/td&gt;
            &lt;td&gt;192.168.100.100&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;slave&lt;/td&gt;
            &lt;td&gt;192.168.100.200&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Abaixo segue o Vagrantfile:
&lt;script src=&#34;//gist.github.com/sebastianwebber/d49ac8507d48c9cfdc4f.js?file=Vagrantfile&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Para utiliza-lo, execute:&lt;/p&gt;

&lt;script src=&#34;//gist.github.com/sebastianwebber/d49ac8507d48c9cfdc4f.js?file=setup.sh&#34;&gt;&lt;/script&gt;

&lt;h3 id=&#34;quanto-a-base-de-dados&#34;&gt;Quanto a base de dados&lt;/h3&gt;

&lt;p&gt;A base de testes adotada é o banco do &lt;a href=&#34;http://www.imdb.com/&#34;&gt;IMDB&lt;/a&gt;. Pra simplificar o processo de importação e teste eu já deixei um dump prontinho na URL abaixo:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://1drv.ms/1TjlPXl&#34;&gt;&lt;code&gt;http://1drv.ms/1TjlPXl&lt;/code&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Detalhes pra importação do dump são os de sempre:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;createdb -U postgres imdb
pg_restore -U postgres -d imdb -Fc --disable-triggers imdb.dump -j 4
vacuumdb -U postgres -d imdb -z
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Na sequência já publico detalhes de como popular e alterar os dados.&lt;/p&gt;

&lt;p&gt;E aí, vai encarar?&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Um rascunho sobre banco de dados e containers</title>
      <link>http://swebber.me/blog/2016/01/21/um-rascunho-sobre-banco-de-dados-e-containers/</link>
      <pubDate>Thu, 21 Jan 2016 17:35:14 -0300</pubDate>
      <author>sebastian@swebber.me (Sebastian Webber)</author>
      <guid>http://swebber.me/blog/2016/01/21/um-rascunho-sobre-banco-de-dados-e-containers/</guid>
      <description>&lt;p&gt;Eu tenho notado que a onda do momento é deixar pra lá a virtualização e passar colocar tudo em container. As pessoas comentam com emoção: minha aplicação rodando no container fica auto-suficiente, configurada conforme os padrões do meu produto e todas as preocupações do fabricante.&lt;/p&gt;

&lt;p&gt;Usar o docker e criar um container é relativamente fácil, se você der uma olhada no google, vai achar uma dezena de tutoriais e dicas infalíveis pra deixar tudo rodando como deve. Vou deixar uns links abaixo pra tentar fazer a minha parte.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/installation/centos/&#34;&gt;Documentação oficial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;O docker tem uma limitação simples: &lt;em&gt;até o momento, ele só roda no linux&lt;/em&gt;. Temos artificios pra usar o docker no Windows e ou Mac, mas a verdade é que mesmo &amp;ldquo;com jeitinho&amp;rdquo;, vai ter uma vm linux rodando o docker por debaixo dos panos. Não sei da Apple, mas &lt;a href=&#34;https://blog.docker.com/2015/08/tp-docker-engine-windows-server-2016/&#34;&gt;a Microsoft ta dando um jeitinho pra rodar ele no Windows Server 2016&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;O que isso quer dizer?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Quer dizer que, no atual momento, docker só funciona no linux.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Se você ficou curioso sobre como usar ele no windows ou mac, dá uma olhada no &lt;a href=&#34;https://kitematic.com/&#34;&gt;Kitematic&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Bom, depois de discurso todo eu quero dizer uma coisa bem simples: Se sua aplicação precisa do Windows pra rodar (seja pelo SQL Server, IIS, etc) acho que esse post não é bem pra você.&lt;/p&gt;

&lt;p&gt;É comum usarmos docker para rodar nossa aplicação web, seja ela como for: ERP rodando em java, blog em php, etc. A idéia é simples: a gente sobe um container com o mínimo pra ela rodar e gentilmente manda o docker rodar muitas instancias dessa mesma imagem simultaneamente. Pensando assim você indaga: Se precisar um balanceador de carga, o que fazemos? Subimos ele num container também. Fácil assim.&lt;/p&gt;

&lt;p&gt;Quer um exemplo? Suponha que tenhamos que publicar um blog feito no wordpress. Wordpress precisa do php e um banco MySQL pra funcionar. Dessa forma, precisamos, &lt;strong&gt;necessariamente&lt;/strong&gt; de 2 containers: 1 de MySQL e outro de apache+php (ou qualquer outro webserver que rode php e te deixe feliz).&lt;/p&gt;

&lt;p&gt;Assim que nosso servidor estiver rodando esses containers e nosso blog imaginario começa a receber muitos acessos, nosso container de apache e php começa a ter dificuldade de responder a todas as requisições e assim, temos a grande idéia de colocar mais um container rodando apache com minha aplicação (wordpress) e assim, ganhamos um problema novo: tenho 2 apaches e nimguém pra balancear o mesmo.&lt;/p&gt;

&lt;p&gt;O que fazer nesse caso? você pode subir um &lt;a href=&#34;https://hub.docker.com/_/haproxy/&#34;&gt;container com o haproxy&lt;/a&gt; e passar a apontar tuas requisições pra ele e ele passar a balancear as conexões entre os apaches. Até que é facil não é? agora, se o site ficar lento denovo, o que a gente faz? aumenta os apaches! Quantos? Quantos forem necessários!!! :D&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Agora, quando baixou a demanda, o que eu faço?&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Diminuo a quantidade de containers em execução, fazendo manualmente um &lt;a href=&#34;https://en.wikipedia.org/wiki/Autoscaling&#34;&gt;autoscaling&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Talvez aqui tenhamos um furo no conceito: a aplicação do wordpress vai eventualmente criar uns arquivos no disco com dados da aplicação (imagens, css, js, etc) e isso a gente pode contornar com uma area de disco compartilhada entre os containers.&lt;/p&gt;

&lt;p&gt;A analogia é simples nesse caso: cada imagem docker tem tudo que eu preciso pra rodar o php+wordpress+coisas+do+blog e o MySQL é quem guarda os dados dinamicos.&lt;/p&gt;

&lt;p&gt;Então vai chegar o temido dia: meu banco rodando no container não dá conta do recado. Você tenta todo tipo de mandinga necessária: tunning, hardware e não tem jeito. Aí, depois de pensar em todos os planos pra aumentar os recursos passa pra pensar em algum tipo de processamento horizontal e nota que vai precisar distribuir a carga e balancear os acessos entre esses nós. Assim, você que já foi doutrinado vai dizer: &amp;ldquo;ótimo! vou colocar a rodar mais um haproxy e vou subir outro container MySQL!&amp;rdquo;. Não, isso não vai funcionar.&lt;/p&gt;

&lt;p&gt;Por que? basicamente por causa da integridade dos dados. Precisamos de algum mecanismo (seja nativo ou não) que garanta que ambas os containers rodando MySQL tenham a mesma informação. Isso não é tão simples: cada fabricante de banco de dados implementa do seu jeito e cada solução de replicação tem seus prós e contras.&lt;/p&gt;

&lt;p&gt;Tá, mas o MySQL não tem replicação? eu não posso usar pra resolver meu problema? Pode. E posso fazer igual como fiz com os apaches+php, apagando os containers conforme ele não for usado? Provavelmente não.&lt;/p&gt;

&lt;p&gt;Aqui é o ponto em questão: bancos de dados não apenas arquivos no disco. Precisamos pensar uma forma diferente de tratar ele pra que funcione bem como de costume.&lt;/p&gt;

&lt;p&gt;Quanto ao armazenamento, tem alguns links que valem a pena dar uma olhada:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker&#34;&gt;http://stackoverflow.com/questions/18496940/how-to-deal-with-persistent-storage-e-g-databases-in-docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://container42.com/2013/12/16/persistent-volumes-with-docker-container-as-volume-pattern/&#34;&gt;http://container42.com/2013/12/16/persistent-volumes-with-docker-container-as-volume-pattern/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.docker.com/engine/userguide/dockervolumes/&#34;&gt;https://docs.docker.com/engine/userguide/dockervolumes/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://container42.com/2014/11/18/data-only-container-madness/&#34;&gt;http://container42.com/2014/11/18/data-only-container-madness/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Continua&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Automatizando os reports do PGBadger</title>
      <link>http://swebber.me/blog/2013/11/04/automatizando-reports-pgbadger/</link>
      <pubDate>Mon, 04 Nov 2013 00:58:11 -0200</pubDate>
      <author>sebastian@swebber.me (Sebastian Webber)</author>
      <guid>http://swebber.me/blog/2013/11/04/automatizando-reports-pgbadger/</guid>
      <description>&lt;p&gt;Minha idéia com esse post é &amp;lsquo;despejar&amp;rsquo; uma série de scripts e configurações pra que o &lt;a href=&#34;http://dalibo.github.io/pgbadger/&#34;&gt;pgbadger&lt;/a&gt; gere quase que automaticamente os reports, seguindo a regra de tempo abaixo:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Report dos últimos 30min&lt;/li&gt;
&lt;li&gt;da última 1h&lt;/li&gt;
&lt;li&gt;das últimas 3h&lt;/li&gt;
&lt;li&gt;das últimas 6h&lt;/li&gt;
&lt;li&gt;do último dia&lt;/li&gt;
&lt;li&gt;da última semana&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Além da configuração padrão, sugerida no site do próprio pgbadger, é necessário configurar o syslog, para que ele direcione os logs do postgres para um arquivo separado, assim, adicione esse trecho no arquivo /etc/rsyslog.conf:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;local0.*        -/var/log/pgsql/pgsql.log
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Pode ser necessário criar o diretório /var/log/pgsql, se explodir qualquer erro aí, confirme se o mesmo foi criado. :D&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Após isso, dê um reload no serviço e os logs do postgres serão criados nesse diretório.&lt;/p&gt;

&lt;p&gt;É necessário configurar o LogRotate para que o mesmo rotacione os logs. Baseado nas regras acima, crie o arquivo &lt;code&gt;/etc/pgsql/cron.logrotate&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;/var/log/pgsql/pgsql.log {
    missingok
    rotate 1488
    nomail
    sharedscripts
    create 0660 root root
    postrotate
    /etc/init.d/rsyslog restart
    /etc/init.d/postgresql-9.2 reload
    endscript
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Crie um script para gerar os reports, chamado update_badger.sh:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;#!/bin/bash

filter_mask=&amp;quot;$1&amp;quot;
filter_mask_cmd=&#39;mmin&#39;
file_name=&amp;quot;/var/www/html&amp;quot;

if [ $filter_mask = &amp;quot;30min&amp;quot; ]; then
  filter_mask=30
  file_name=&amp;quot;${file_name}/index.html&amp;quot;
elif [ $filter_mask = &amp;quot;1h&amp;quot; ]; then
  filter_mask=60
  file_name=&amp;quot;${file_name}/last-1h.html&amp;quot;
elif [ $filter_mask = &amp;quot;3h&amp;quot; ]; then
  filter_mask=300
  file_name=&amp;quot;${file_name}/last-3h.html&amp;quot;
elif [ $filter_mask = &amp;quot;6h&amp;quot; ]; then
  filter_mask=600
  file_name=&amp;quot;${file_name}/last-6h.html&amp;quot;
elif [ $filter_mask = &amp;quot;1d&amp;quot; ]; then
  filter_mask=1
  filter_mask_cmd=&#39;mtime&#39;
  file_name=&amp;quot;${file_nam3e}/last-day.html&amp;quot;
elif [ $filter_mask = &amp;quot;1w&amp;quot; ]; then
  filter_mask=7
  filter_mask_cmd=&#39;mtime&#39;
  file_name=&amp;quot;${file_name}/last-week.html&amp;quot;
fi

echo
echo $(date) - Generating ${file_name} file...
echo
/usr/bin/pgbadger $(/bin/find /var/log/pgsql/ -${filter_mask_cmd} -$filter_mask -type f) -o ${file_name}
/bin/chown apache:apache ${file_name}
/bin/chmod 755 ${file_name}

if [ ${filter_mask} -eq 30 ]; then
  echo $(date) - Rotating log file
  /usr/sbin/logrotate -f /etc/pgsql/cron.logrotate
fi
echo $(date) - Done.
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;Note que nesse script, o log rotate é chamado (com a configuração descrita anteriormente) a cada 30min. Assim, não é necessário configurar o crontab ou similar pra fazer esse trabalho sujo. ;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Agora, agende a geração dos reports no cron:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# pgbadger reports
*/30 * * * * /opt/resources/update_badger.sh 30min &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 */1 * * * /opt/resources/update_badger.sh 1h &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 */3 * * * /opt/resources/update_badger.sh 3h &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 */6 * * * /opt/resources/update_badger.sh 6h &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 00 * * * /opt/resources/update_badger.sh 1d &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
00 00 * * Sat /opt/resources/update_badger.sh 1w &amp;gt;&amp;gt; /var/log/pgbagder.log 2&amp;gt;&amp;amp;1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Pra finalizar, eu fiz uma pequena modificação no pgbadger, para que ele mostre um pequeno menu dropdown com os horários dos reports disponíveis. Você pode fazer download do mesmo no github: &lt;a href=&#34;http://github.com/sebastianwebber/pgbadger&#34;&gt;https://github.com/sebastianwebber/pgbadger&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Todo caso, fica aí um screenshot da minima modificação que fiz (só pra dar um gostinho):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://swebber.me/wp-content/uploads/2013/11/badger_custom.png&#34; alt=&#34;screenshot&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Utilizando o log CSV do PostgreSQL</title>
      <link>http://swebber.me/blog/2010/08/14/utilizando-o-log-csv-do-postgresql/</link>
      <pubDate>Sat, 14 Aug 2010 17:32:36 -0300</pubDate>
      <author>sebastian@swebber.me (Sebastian Webber)</author>
      <guid>http://swebber.me/blog/2010/08/14/utilizando-o-log-csv-do-postgresql/</guid>
      <description>&lt;p&gt;Uma das novidades bacanas da versão 8.3 do PostgreSQL foi a possibilidade de gerar os logs do banco no formato &lt;a href=&#34;http://pt.wikipedia.org/wiki/Comma-separated_values&#34;&gt;CSV&lt;/a&gt;. Quando eu precisei de uma forma mais eficiente de analisar os logs do banco eu assumi o seguinte raciocínio: &amp;ldquo;com o csv eu posso criar minha super aplicação .net para extrair os dados e dai pensei: se fosse só uma tabela, é só dar um select!&amp;ldquo;. Abaixo eu dou mais detalhes de como isso faz sentido.&lt;/p&gt;

&lt;p&gt;Na &lt;a href=&#34;http://www.postgresql.org/docs/8.4/static/&#34;&gt;documentação&lt;/a&gt; eu encontrei toda a &lt;a href=&#34;http://www.postgresql.org/docs/8.4/static/runtime-config-logging.html#RUNTIME-CONFIG-LOGGING-CSVLOG&#34;&gt;estrutura da tabela e como importar o arquivo&lt;/a&gt;. Mas antes de começarmos, vamos alterar algumas configurações no postgresql.conf:&lt;/p&gt;

&lt;p&gt;Segue exemplo das configurações no postgresql.conf:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# habilito o log em csv
log_destination = &#39;csvlog&#39;
# habilito o coletor de estatisticas
logging_collector = on
# defino que grave no log a duração dos comandos executados
log_duration = on
# defino para gravar todas as consultas no log
log_statement = &#39;all&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Após alterar as configurações, reinicie o serviço.&lt;/p&gt;

&lt;p&gt;Segue a estrutura da tabela que iremos importar o log:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TABLE postgres_log
(
  log_time timestamp(3) with time zone,
  user_name text,
  database_name text,
  process_id integer,
  connection_from text,
  session_id text,
  session_line_num bigint,
  command_tag text,
  session_start_time timestamp with time zone,
  virtual_transaction_id text,
  transaction_id bigint,
  error_severity text,
  sql_state_code text,
  message text,
  detail text,
  hint text,
  internal_query text,
  internal_query_pos integer,
  context text,
  query text,
  query_pos integer,
  location text,
  PRIMARY KEY (session_id, session_line_num)
);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Com a tabela criada, vamos importar o log (Repita o processo sempre que quiser atualizar a tabela com os dados do arquivo de log):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;TRUNCATE postgres_log;
COPY postgres_log FROM &#39;/caminho/do/pgdata/pg_log/main_log.csv&#39; WITH csv;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Com a tabela atualizada podemos criar diversas consultas, como não sou muito criativo, vou &lt;a href=&#34;http://pgfouine.projects.postgresql.org/reports/sample_default.html#normalizedqueriesmostfrequentreport&#34;&gt;roubar o exemplo do pgFouine&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;Most frequent queries:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-sql&#34;&gt;CREATE TEMP SEQUENCE rank_seq;
WITH
  custom_log AS ( 
    SELECT
      REGEXP_REPLACE(REGEXP_REPLACE(MESSAGE, &#39;[0-9]{1,}&#39;, &#39;0&#39;, &#39;g&#39;), &#39;&#39;&#39;.*?&#39;&#39;&#39;, &#39;&#39;&#39;&#39;&#39;&#39;, &#39;g&#39;) AS MESSAGE,
      session_id,
      session_line_num
    FROM
      postgres_log
  ), summary AS (
    SELECT
      substring(custom_log.message, 12, LENGTH(custom_log.message)) AS consulta,
      COUNT(custom_log.message) AS quantidade_execucoes,
      AVG(SUBSTR(dur.message, 10, LENGTH(dur.message))::interval) AS tempo_medio,
      SUM(SUBSTR(dur.message, 10, LENGTH(dur.message))::interval) AS tempo_total
    FROM
      custom_log
      LEFT JOIN postgres_log dur
      ON
        custom_log.session_id               = dur.session_id
        AND custom_log.session_line_num + 1 = dur.session_line_num
    WHERE
      custom_log.message LIKE &#39;statement%&#39;
      AND dur.message    LIKE &#39;duration%&#39;
    GROUP BY
      custom_log.message
    ORDER BY
      2 DESC
    LIMIT
      10
  )
  SELECT
      nextval(&#39;rank_seq&#39;)::INT AS rank,
      summary.tempo_medio AS AvDuration,
      summary.quantidade_execucoes::INT AS TimesExecuted,
      summary.tempo_total AS TotalDuration,
      summary.consulta::text AS Query
    FROM
      summary;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Espero que seja útil.&lt;/p&gt;

&lt;p&gt;[]&amp;rsquo;s&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Compilando o PostgreSQL no RHEL 5</title>
      <link>http://swebber.me/blog/2010/07/14/compilando-postgresql-rhel-5/</link>
      <pubDate>Wed, 14 Jul 2010 02:13:35 -0300</pubDate>
      <author>sebastian@swebber.me (Sebastian Webber)</author>
      <guid>http://swebber.me/blog/2010/07/14/compilando-postgresql-rhel-5/</guid>
      <description>&lt;p&gt;Confesso que não é muito diferente do debian, é só instalar as libs necessárias e o ./configure, make e make installl de sempre. Mas talvez isso possa ajudar alguém. Segue:&lt;/p&gt;

&lt;p&gt;Instale as bibliotecas necessárias:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;yum install bison flex zlib zlib-devel readline readline-devel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Baixe o postgresql (no exemplo estou usando uma versão antiga e tenho que baixar ela do ftp-archive):&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;wget -c ftp://ftp-archives.postgresql.org/pub/source/v8.2.4/postgresql-8.2.4.tar.bz2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Descompacte e instale:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;tar xvjf postgresql-8.2.4.tar.bz2
cd postgresql-8.2.4
./configure --bindir=/usr/bin
make
make install
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Agora crie o usuário postgres e inicialize o cluster*:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;adduser postgres
mkdir /usr/local/pgsql/data
chown -R postgres /usr/local/pgsql
su - postgres
/usr/local/pgsql/bin/initdb -D /usr/local/pgsql/data
logout
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;OBS:&lt;/strong&gt; para fins didaticos, criei o cluster no diretório aonde o postgres foi instalado. O ideal é que o diretório do cluster fique em discos e/ou partições separadas. O &lt;a href=&#34;http://savepoint.blog.br&#34;&gt;blog do telles&lt;/a&gt; tem um &lt;a href=&#34;http://savepoint.blog.br/postgresql-discos-cia/&#34;&gt;artigo muito interessante a respeito dos discos e partições&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Crie o script de inicialização, inicie o banco e habilite a inicialização automática:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cp contrib/start-scripts/linux /etc/init.d/postgresql
chmod +x /etc/init.d/postgresql
service postgresql start
chkconfig postgresql on
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Um abraço!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>